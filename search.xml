<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Convolutional Neural Network卷积神经网络</title>
      <link href="2020/10/28/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>2020/10/28/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="The-whole-CNN"><a href="#The-whole-CNN" class="headerlink" title="The whole CNN"></a>The whole CNN</h1><img src="/2020/10/28/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.png" class><p>CNN工作原理：输入一张图片，让他经历一系列卷积层、池化层和全连接层，最终得到输出，输出结果可以是图像内容的单独分类或者分类的概率。</p><p>整个CNN包括三个层次：输入层、卷积层、全连接层</p><p>输入层：输入图片；</p><p>卷积层：一个卷积层包括卷积和池化两个步骤，构成一个单元，一张图片经过卷积层之后将会得到一张新的图片；可以经过多次卷积处理；</p><p>全连接层：Fully Connected Feedforward network</p><h1 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h1><img src="/2020/10/28/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.gif" class><h2 id><a href="#" class="headerlink" title></a></h2><p>卷积神经网络是含有卷积层的神经网络。我们以二维为例，包含有高H和宽W两个维度，通常用来处理图像数据。</p><h2 id="卷积核（滤波器filter）"><a href="#卷积核（滤波器filter）" class="headerlink" title="卷积核（滤波器filter）"></a>卷积核（滤波器filter）</h2><p>二维卷积层就是把二维输入数组与二维卷积核进行内积运算得到一个二维输出数组。</p><p><strong>卷积核又称为过滤器filter</strong>，其大小取决于卷积核的高和宽，通常大小应该是奇数1、3、5、7……。我们以下面这个图作为展示：</p><img src="/2020/10/28/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.png" class><p>将输入数组的深色区域（卷积核窗口）与卷积核进行内积得到一个输出数组的深色区域数字，即0×0+1×1+3×2+4×3=19，然后从左到右、从上到下依次移动卷积核窗口并求内积即可得到输出数组。其中输入数组的深色区域大小取决于卷积核的大小，即两者同高同宽。</p><p>卷积核的选择决定对图像的处理效果，可以看作是特征标识符，将图像的某些特征（直边缘、原色、锐化等）表示出来，其他特征尽可能忽略掉。常用的有图像锐化滤波器（Sharpness Filter）、边缘检测滤波器（Edge Detection Filter）、浮雕滤波器（Embossing Filter)</p><h2 id="填充Padding和步幅stride"><a href="#填充Padding和步幅stride" class="headerlink" title="填充Padding和步幅stride"></a>填充Padding和步幅stride</h2><p>在对输入数组依次移动求内积的过程中，边界元素（某一行或某一列）往往无法单独进行内积运算，因此我们引入填充，填充是指在输入数组的高宽两侧填充元素（通常为0）。</p><p>步幅是指卷积核窗口在输入数组上每次移动的行数或列数；</p><p>填充可以增加输出的高和宽，通常用来使输出与输入具有相同的高和宽；</p><p>步幅可以减小输出的高和宽，步幅变大之后输出数组的维数就会降低；</p><h2 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h2><p>上面我们讲的都是二维输入数组，适用于纯色图片，但是不适用于彩色图片。彩色图片是由RGB三种颜色叠加形成，相当于是三个二维数组，我们称为三个通道Chanel。</p><p>多输入通道对应的卷积核也是多通道，输出也是多通道。</p><h1 id="池化层Pooling（也成为下采样层down-sampling）"><a href="#池化层Pooling（也成为下采样层down-sampling）" class="headerlink" title="池化层Pooling（也成为下采样层down sampling）"></a>池化层Pooling（也成为下采样层down sampling）</h1><p>池化层每次对输入数据的一个固定形状窗口（称为池化窗口）中的元素进行计算输出。卷积层是把输入层与卷积核求内积，而池化层则是计算池化窗口内元素的最大值Max Pooling或平均值。</p><p>池化层可以压缩数据，减少参数数量。</p><p>填充和步幅都同上。</p><p>参考：</p><p><a href="http://zh.d2l.ai/chapter_convolutional-neural-networks/conv-layer.html">http://zh.d2l.ai/chapter_convolutional-neural-networks/conv-layer.html</a></p><p><a href="https://blog.csdn.net/zouxy09/article/details/49080029">https://blog.csdn.net/zouxy09/article/details/49080029</a></p><p>《机器学习（李宏毅2020spring）》</p>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习资源汇总</title>
      <link href="2020/10/27/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/"/>
      <url>2020/10/27/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="论文网站"><a href="#论文网站" class="headerlink" title="论文网站"></a>论文网站</h1><p><a href="https://dblp.uni-trier.de/">DBLP</a>：计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的继承数据库系统。</p><p><a href="https://arxiv.org/">arXiv</a>：（<em>X</em> 依<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E5%B8%8C%E8%87%98%E6%96%87">希腊文</a>的 <a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%CE%A7">χ</a> 发音，读音如英语的 <a href="https://link.zhihu.com/?target=https://zh.wiktionary.org/wiki/archive">archive</a> ）是一个收集<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E7%89%A9%E7%90%86%E5%AD%B8">物理学</a>、<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E6%95%B8%E5%AD%B8">数学</a>、<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8">计算机科学、</a><a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E7%94%9F%E7%89%A9%E5%AD%B8">生物学</a>与<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E6%95%B0%E7%90%86%E7%BB%8F%E6%B5%8E%E5%AD%A6">数理经济学</a>的<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E8%AB%96%E6%96%87">论文</a><a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/%E9%A0%90%E5%8D%B0%E6%9C%AC">预印本</a>的网站，始于1991年8月14日。截至2008年10月，arXiv.org已收集超过50万篇预印本[<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/ArXiv%23cite_note-2">2]</a>[<a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/ArXiv%23cite_note-3">3]</a>；至2014年底，藏量达到1百万篇。截至2016年10月，提交率已达每月超过10,000篇。</p><p><a href="https://www.ieee.org/">IEEE</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>学习日志10月26日-11月11日</title>
      <link href="2020/10/26/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%9710%E6%9C%8826%E6%97%A5-11%E6%9C%881%E6%97%A5/"/>
      <url>2020/10/26/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%9710%E6%9C%8826%E6%97%A5-11%E6%9C%881%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<blockquote><p>此页面用来记录一周学习情况，仅作记录之用。</p></blockquote><h1 id="2020年10月17日"><a href="#2020年10月17日" class="headerlink" title="2020年10月17日"></a>2020年10月17日</h1><ul><li><input checked disabled type="checkbox"> 读书《曾国藩家书》30%</li><li><input checked disabled type="checkbox"> 背单词500个</li><li><input checked disabled type="checkbox"> Graph Neural Network-2</li><li><input checked disabled type="checkbox"> Recurrent Neural Network-1</li><li><input checked disabled type="checkbox"> Cesium开发入门</li><li><input checked disabled type="checkbox"> 配置GPU服务器环境</li></ul><h1 id="2020年10月16日"><a href="#2020年10月16日" class="headerlink" title="2020年10月16日"></a>2020年10月16日</h1><ul><li><input checked disabled type="checkbox"> 读书《曾国藩家书》19%</li><li><input checked disabled type="checkbox"> 背单词400个</li><li><input checked disabled type="checkbox"> Convolution Neural Network</li><li><input checked disabled type="checkbox"> Graph Neural Network-1</li><li><input checked disabled type="checkbox"> Cesium开发入门</li><li><input checked disabled type="checkbox"> 打羽毛球</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Learning Log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习（李宏毅2020spring）》作业2：Classification</title>
      <link href="2020/10/21/my-hw2-classification/"/>
      <url>2020/10/21/my-hw2-classification/</url>
      
        <content type="html"><![CDATA[<h1 id="作业说明"><a href="#作业说明" class="headerlink" title="作业说明"></a>作业说明</h1><h2 id="作业要求"><a href="#作业要求" class="headerlink" title="作业要求"></a>作业要求</h2><p>根据人们的个人资料，判断其年收入是否高于5000美元，典型的二元分类问题，通过logistic regression与generative model实现</p><h2 id="数据集说明"><a href="#数据集说明" class="headerlink" title="数据集说明"></a>数据集说明</h2><p>X_train、Y_train和X_test是经过处理的数据集，可以直接使用，其他两个train.csv和test.csv为了提供额外信息</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/HL-space/p/10785225.html">https://www.cnblogs.com/HL-space/p/10785225.html</a><br><a href="https://mrsuncodes.github.io/2020/03/19/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%BA%8C%E8%AF%BE%E4%BD%9C%E4%B8%9A/">https://mrsuncodes.github.io/2020/03/19/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%BA%8C%E8%AF%BE%E4%BD%9C%E4%B8%9A/</a></p><p>李宏毅老师提供的源代码</p><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>对每个属性做归一化，处理后将其分为训练集与测试集</p><p><a href="https://blog.csdn.net/pipisorry/article/details/52247379">https://blog.csdn.net/pipisorry/article/details/52247379</a><br>这篇文章对数据的归一化处理做了讲解，可以去这里看看，集中归一化方法都用到了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据，路径要和自己的路径保持一致</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X_train_fpath = <span class="string">&#x27;./X_train2&#x27;</span></span><br><span class="line">Y_train_fpath = <span class="string">&#x27;./Y_train2&#x27;</span></span><br><span class="line">X_test_fpath = <span class="string">&#x27;./X_test2&#x27;</span></span><br><span class="line">output_fpath = <span class="string">&#x27;./output_&#123;&#125;.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将csv文件转换为numpy array</span></span><br><span class="line"><span class="comment">#源文件是通过‘，’作为分隔，每个值都有，无空值</span></span><br><span class="line"><span class="keyword">with</span> open(X_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_train = np.array([line.strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype = float)</span><br><span class="line"><span class="keyword">with</span> open(Y_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    Y_train = np.array([line.strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype = float)</span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_test = np.array([line.strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype = float)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_normalize</span>(<span class="params">X, train = True, specified_column = None, X_mean = None, X_std = None</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对X的特定列进行归一化处理</span></span><br><span class="line"><span class="string">    处理数据的过程中，训练数据的平均值和标准差会被重复使用</span></span><br><span class="line"><span class="string">    input：</span></span><br><span class="line"><span class="string">    X：要被处理的数据集</span></span><br><span class="line"><span class="string">    train：处理训练数据时为true，处理测试数据时为false</span></span><br><span class="line"><span class="string">    specified_column：特定列将会进行归一化处理，如果为None，所有列都会进行归一化处理</span></span><br><span class="line"><span class="string">    X_mean：训练数据的平均值</span></span><br><span class="line"><span class="string">    X_std：标准差</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    X 、X_mean、X_std</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> specified_column == <span class="literal">None</span>:</span><br><span class="line">        specified_column = np.arange(X.shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        X_mean = np.mean(X[:, specified_column] ,<span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        X_std  = np.std(X[:, specified_column], <span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    X[:,specified_column] = (X[:, specified_column] - X_mean) / (X_std + <span class="number">1e-8</span>)</span><br><span class="line">     </span><br><span class="line">    <span class="keyword">return</span> X, X_mean, X_std</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_train_dev_split</span>(<span class="params">X, Y, dev_ratio = <span class="number">0.25</span></span>):</span></span><br><span class="line">    <span class="comment"># 将数据划分为training set and development set.</span></span><br><span class="line">    train_size = int(len(X) * (<span class="number">1</span> - dev_ratio))</span><br><span class="line">    <span class="keyword">return</span> X[:train_size], Y[:train_size], X[train_size:], Y[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据进行归一化处理</span></span><br><span class="line">X_train, X_mean, X_std = _normalize(X_train, train = <span class="literal">True</span>)</span><br><span class="line">X_test, _, _= _normalize(X_test, train = <span class="literal">False</span>, specified_column = <span class="literal">None</span>, X_mean = X_mean, X_std = X_std)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#数据划分为training set and development set</span></span><br><span class="line">dev_ratio = <span class="number">0.1</span></span><br><span class="line">X_train, Y_train, X_dev, Y_dev = _train_dev_split(X_train, Y_train, dev_ratio = dev_ratio)</span><br><span class="line"></span><br><span class="line">train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">dev_size = X_dev.shape[<span class="number">0</span>]</span><br><span class="line">test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">data_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line">print(<span class="string">&#x27;Size of training set: &#123;&#125;&#x27;</span>.format(train_size))</span><br><span class="line">print(<span class="string">&#x27;Size of development set: &#123;&#125;&#x27;</span>.format(dev_size))</span><br><span class="line">print(<span class="string">&#x27;Size of testing set: &#123;&#125;&#x27;</span>.format(test_size))</span><br><span class="line">print(<span class="string">&#x27;Dimension of data: &#123;&#125;&#x27;</span>.format(data_dim))</span><br></pre></td></tr></table></figure><pre><code>Size of training set: 48830Size of development set: 5426Size of testing set: 27622Dimension of data: 510</code></pre><h1 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h1><p>这个几个函数在后面会重复使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_shuffle</span>(<span class="params">X, Y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    把数据的行打乱，其中X， Y为等长度数据（第一维相等）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    randomize = np.arange(len(X))</span><br><span class="line">    np.random.shuffle(randomize)</span><br><span class="line">    <span class="keyword">return</span> (X[randomize], Y[randomize])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span>(<span class="params">z</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    sigmoid函数的功能是求概率，为了防止溢出，设置了最大最小输出值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.clip(<span class="number">1</span> / (<span class="number">1.0</span> + np.exp(-z)), <span class="number">1e-8</span>, <span class="number">1</span> - (<span class="number">1e-8</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_f</span>(<span class="params">X, w, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    这个是逻辑回归函数f(w, b) = sigmoid(wi*xi + b)</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    X:数据集；W：为权重；b:为误差</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#matmul为矩阵的乘法操作</span></span><br><span class="line">    <span class="keyword">return</span> _sigmoid(np.matmul(X, w) + b)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict</span>(<span class="params">X, w, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通过调用逻辑回归函数对X的每一行返回一个真正的预测值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#round将f的结果四舍五入，astype规定其为int类型，即最终返回的是0或1</span></span><br><span class="line">    <span class="keyword">return</span> np.round(_f(X, w, b)).astype(np.int)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_accuracy</span>(<span class="params">Y_pred, Y_label</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算预测的准确性，如果预测正确，返回值为0，否则返回值为1</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    acc = <span class="number">1</span> - np.mean(np.abs(Y_pred - Y_label))</span><br><span class="line">    <span class="keyword">return</span> acc</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_cross_entropy_loss</span>(<span class="params">y_pred, Y_label</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    求交叉熵</span></span><br><span class="line"><span class="string">    input：</span></span><br><span class="line"><span class="string">    y_pred：预测的可能性，为float类型向量</span></span><br><span class="line"><span class="string">    Y_label： 真正的标签值，为bool类型向量</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    output：</span></span><br><span class="line"><span class="string">    交叉熵</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cross_entropy = -np.dot(Y_label, np.log(y_pred)) - np.dot((<span class="number">1</span> - Y_label), np.log(<span class="number">1</span> - y_pred))</span><br><span class="line">    <span class="keyword">return</span> cross_entropy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gradient</span>(<span class="params">X, Y_label, w, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    这个功能是计算交叉熵损失函数的梯度，对w，b求导</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y_pred = _f(X, w, b)</span><br><span class="line">    pred_error = Y_label - y_pred</span><br><span class="line">    w_grad = -np.sum(pred_error * X.T, <span class="number">1</span>)</span><br><span class="line">    b_grad = -np.sum(pred_error)</span><br><span class="line">    <span class="keyword">return</span> w_grad, b_grad</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对w，b初始化为0</span></span><br><span class="line">w = np.zeros((data_dim,)) </span><br><span class="line">b = np.zeros((<span class="number">1</span>,))</span><br><span class="line"></span><br><span class="line"><span class="comment">#对一些参数进行训练  </span></span><br><span class="line"><span class="comment">#可以进行调整这几个参数，分别为迭代次数、小批次包含的数据个数、学习率</span></span><br><span class="line">max_iter = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">15</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把每次的损失和准确度都通过图表展示出来</span></span><br><span class="line"><span class="comment">#分别为训练集损失、验证集损失、训练集正确率、验证集正确率</span></span><br><span class="line">train_loss = []</span><br><span class="line">dev_loss = []</span><br><span class="line">train_acc = []</span><br><span class="line">dev_acc = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算参数更新的次数</span></span><br><span class="line">step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#重复多轮训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(max_iter):</span><br><span class="line">    <span class="comment"># 每轮开始之前打乱数据</span></span><br><span class="line">    X_train, Y_train = _shuffle(X_train, Y_train)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 最小批次的训练</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(int(np.floor(train_size / batch_size))):</span><br><span class="line">        X = X_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line">        Y = Y_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        w_grad, b_grad = _gradient(X, Y, w, b)</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#梯度更新，学习率也随之改变，这个学习率有点简单，直接用学习率除以更新次数的跟</span></span><br><span class="line">        w = w - learning_rate/np.sqrt(step) * w_grad</span><br><span class="line">        b = b - learning_rate/np.sqrt(step) * b_grad</span><br><span class="line"></span><br><span class="line">        step = step + <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment">#计算训练集和验证集</span></span><br><span class="line">    y_train_pred = _f(X_train, w, b)<span class="comment">#此时为float类型</span></span><br><span class="line">    Y_train_pred = np.round(y_train_pred)<span class="comment">#转换为bool类型</span></span><br><span class="line">    train_acc.append(_accuracy(Y_train_pred, Y_train))</span><br><span class="line">    train_loss.append(_cross_entropy_loss(y_train_pred, Y_train) / train_size)</span><br><span class="line"></span><br><span class="line">    y_dev_pred = _f(X_dev, w, b) </span><br><span class="line">    Y_dev_pred = np.round(y_dev_pred) </span><br><span class="line">    dev_acc.append(_accuracy(Y_dev_pred, Y_dev))</span><br><span class="line">    dev_loss.append(_cross_entropy_loss(y_dev_pred, Y_dev) / dev_size)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Training loss: &#123;&#125;&#x27;</span>.format(train_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">&#x27;Development loss: &#123;&#125;&#x27;</span>.format(dev_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">&#x27;Training accuracy: &#123;&#125;&#x27;</span>.format(train_acc[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">&#x27;Development accuracy: &#123;&#125;&#x27;</span>.format(dev_acc[<span class="number">-1</span>]))</span><br></pre></td></tr></table></figure><pre><code>Training loss: 0.265942625291867Development loss: 0.2854362130041641Training accuracy: 0.8858693426172435Development accuracy: 0.8781791374861777</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失曲线</span></span><br><span class="line">plt.plot(train_loss)</span><br><span class="line">plt.plot(dev_loss)</span><br><span class="line">plt.title(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;loss.png&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准确率曲线</span></span><br><span class="line">plt.plot(train_acc)</span><br><span class="line">plt.plot(dev_acc)</span><br><span class="line">plt.title(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;acc.png&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2020/10/21/my-hw2-classification/output_8_0.png" class><img src="/2020/10/21/my-hw2-classification/output_8_0.png" class><h1 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h1><p>把test的数据进行预测得到预测结果<br>结果保存在output2_logistic</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">predictions = _predict(X_test, w, b)</span><br><span class="line"><span class="keyword">with</span> open(output_fpath.format(<span class="string">&#x27;logistic&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;id,label\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span>  enumerate(predictions):</span><br><span class="line">        f.write(<span class="string">&#x27;&#123;&#125;,&#123;&#125;\n&#x27;</span>.format(i, label))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the most significant weights</span></span><br><span class="line"><span class="comment"># 找到权重中最大的前十项，</span></span><br><span class="line">ind = np.argsort(np.abs(w))[::<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    content = f.readline().strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">features = np.array(content)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ind[<span class="number">0</span>:<span class="number">10</span>]:</span><br><span class="line">    print(features[i], w[i])</span><br></pre></td></tr></table></figure><pre><code> Unemployed full-time 1.1225676433808978 Not in universe -1.0573592082887484 Other Rel &lt;18 never married RP of subfamily -0.912973403518828 Child 18+ ever marr Not in a subfamily -0.8705099085602619 1 0.7950300190669547 Spouse of householder -0.750112419980567 Other Rel &lt;18 ever marr RP of subfamily -0.7491036728017868 Italy -0.7240219980088511capital losses 0.6611812623046104id 0.5751429906332644</code></pre><h1 id="第二种方法：generative-model"><a href="#第二种方法：generative-model" class="headerlink" title="第二种方法：generative model"></a>第二种方法：generative model</h1><p>训练集与测试集的处理方法与逻辑回归一样，因为generativemodel有可解析的最佳解，因此不必使用到验证集</p><h2 id="数据处理与归一化"><a href="#数据处理与归一化" class="headerlink" title="数据处理与归一化"></a>数据处理与归一化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Parse csv files to numpy array</span></span><br><span class="line"><span class="keyword">with</span> open(X_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_train = np.array([line.strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype = float)</span><br><span class="line"><span class="keyword">with</span> open(Y_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    Y_train = np.array([line.strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype = float)</span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_test = np.array([line.strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype = float)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize training and testing data</span></span><br><span class="line">X_train, X_mean, X_std = _normalize(X_train, train = <span class="literal">True</span>)</span><br><span class="line">X_test, _, _= _normalize(X_test, train = <span class="literal">False</span>, specified_column = <span class="literal">None</span>, X_mean = X_mean, X_std = X_std)</span><br></pre></td></tr></table></figure><h2 id="求两个类别的平均值和协方差"><a href="#求两个类别的平均值和协方差" class="headerlink" title="求两个类别的平均值和协方差"></a>求两个类别的平均值和协方差</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compute in-class mean</span></span><br><span class="line"><span class="comment">#将数据的两个类别分开</span></span><br><span class="line">X_train_0 = np.array([x <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(X_train, Y_train) <span class="keyword">if</span> y == <span class="number">0</span>])</span><br><span class="line">X_train_1 = np.array([x <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(X_train, Y_train) <span class="keyword">if</span> y == <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">mean_0 = np.mean(X_train_0, axis = <span class="number">0</span>)</span><br><span class="line">mean_1 = np.mean(X_train_1, axis = <span class="number">0</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute in-class covariance</span></span><br><span class="line">cov_0 = np.zeros((data_dim, data_dim))</span><br><span class="line">cov_1 = np.zeros((data_dim, data_dim))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> X_train_0:</span><br><span class="line">    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / X_train_0.shape[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> X_train_1:</span><br><span class="line">    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / X_train_1.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shared covariance is taken as a weighted average of individual in-class covariance.</span></span><br><span class="line">cov = (cov_0 * X_train_0.shape[<span class="number">0</span>] + cov_1 * X_train_1.shape[<span class="number">0</span>]) / (X_train_0.shape[<span class="number">0</span>] + X_train_1.shape[<span class="number">0</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compute inverse of covariance matrix.</span></span><br><span class="line"><span class="comment"># Since covariance matrix may be nearly singular, np.linalg.inv() may give a large numerical error.</span></span><br><span class="line"><span class="comment"># Via SVD decomposition, one can get matrix inverse efficiently and accurately.</span></span><br><span class="line">u, s, v = np.linalg.svd(cov, full_matrices=<span class="literal">False</span>)</span><br><span class="line">inv = np.matmul(v.T * <span class="number">1</span> / s, u.T)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directly compute weights and bias</span></span><br><span class="line">w = np.dot(inv, mean_0 - mean_1)</span><br><span class="line">b =  (<span class="number">-0.5</span>) * np.dot(mean_0, np.dot(inv, mean_0)) + <span class="number">0.5</span> * np.dot(mean_1, np.dot(inv, mean_1))\</span><br><span class="line">    + np.log(float(X_train_0.shape[<span class="number">0</span>]) / X_train_1.shape[<span class="number">0</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute accuracy on training set</span></span><br><span class="line">Y_train_pred = <span class="number">1</span> - _predict(X_train, w, b)</span><br><span class="line">print(<span class="string">&#x27;Training accuracy: &#123;&#125;&#x27;</span>.format(_accuracy(Y_train_pred, Y_train)))</span><br></pre></td></tr></table></figure><pre><code>Training accuracy: 0.873820406959599</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Predict testing labels</span></span><br><span class="line">predictions = <span class="number">1</span> - _predict(X_test, w, b)</span><br><span class="line"><span class="keyword">with</span> open(output_fpath.format(<span class="string">&#x27;generative&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;id,label\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span>  enumerate(predictions):</span><br><span class="line">        f.write(<span class="string">&#x27;&#123;&#125;,&#123;&#125;\n&#x27;</span>.format(i, label))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the most significant weights</span></span><br><span class="line">ind = np.argsort(np.abs(w))[::<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    content = f.readline().strip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">features = np.array(content)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ind[<span class="number">0</span>:<span class="number">10</span>]:</span><br><span class="line">    print(features[i], w[i])</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Agriculture <span class="number">7.5625</span></span><br><span class="line"> <span class="number">41</span> <span class="number">-7.5</span></span><br><span class="line"> Retail trade <span class="number">6.828125</span></span><br><span class="line"> Forestry <span class="keyword">and</span> fisheries <span class="number">6.03125</span></span><br><span class="line"> <span class="number">29</span> <span class="number">-6.0</span></span><br><span class="line"> <span class="number">35</span> <span class="number">5.265625</span></span><br><span class="line"> <span class="number">34</span> <span class="number">-5.15625</span></span><br><span class="line"> Sales <span class="number">-5.1171875</span></span><br><span class="line"> Construction <span class="number">-5.111328125</span></span><br><span class="line"> <span class="number">37</span> <span class="number">-4.79296875</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习（李宏毅2020spring）》作业1：Regression</title>
      <link href="2020/10/19/my-hw1-regression/"/>
      <url>2020/10/19/my-hw1-regression/</url>
      
        <content type="html"><![CDATA[<h1 id="作业要求、参考文献"><a href="#作业要求、参考文献" class="headerlink" title="作业要求、参考文献"></a>作业要求、参考文献</h1><h2 id="作业要求"><a href="#作业要求" class="headerlink" title="作业要求"></a>作业要求</h2><p>根据前9个小时的18个features（包含PM2.5）预测第十个小时的PM2.5</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html</a><br>基本是按照参考代码来的，加入了一些注释更方便理解</p><p>另外所有的print都可以去掉，加上只是为了检验是否输出正确的数据</p><h1 id="加载训练集数据"><a href="#加载训练集数据" class="headerlink" title="加载训练集数据"></a>加载训练集数据</h1><p>train.csv 的資料為 12 個月中，每個月取 20 天，每天 24 小時的資料(每小時資料有 18 個 features)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./hw1_train.csv&#x27;</span>, encoding = <span class="string">&#x27;big5&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h1><p>取出需要的数值部分，即从第四列开始取数据<br>把输出的数据与train.csv对比即可发现不同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = data.iloc[:, <span class="number">3</span>:]</span><br><span class="line">data[data == <span class="string">&#x27;NR&#x27;</span>] = <span class="number">0</span></span><br><span class="line">raw_data = data.to_numpy()</span><br></pre></td></tr></table></figure><h1 id="提取特征值1"><a href="#提取特征值1" class="headerlink" title="提取特征值1"></a>提取特征值1</h1><p>将数据转置，即将原始4230×18按照每个月分组为12个月中的18个features×480Hours</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">month_data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> month <span class="keyword">in</span> range(<span class="number">12</span>):</span><br><span class="line">    sample = np.empty([<span class="number">18</span>, <span class="number">480</span>])</span><br><span class="line">    <span class="keyword">for</span> day <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        sample[:, day * <span class="number">24</span> : (day + <span class="number">1</span>) * <span class="number">24</span>] = raw_data[<span class="number">18</span> * (<span class="number">20</span> * month + day) : <span class="number">18</span> * (<span class="number">20</span> * month + day + <span class="number">1</span>), :]</span><br><span class="line">    month_data[month] = sample</span><br><span class="line">    </span><br><span class="line">print(month_data)</span><br></pre></td></tr></table></figure><h1 id="提取特征2"><a href="#提取特征2" class="headerlink" title="提取特征2"></a>提取特征2</h1><p>每个月有20*24=480h，每9个小时形成一个data，每个月就会有471个data，总资料数目是471×12笔，每笔数据中有9×18个features；<br>对应的target（第10个小时的PM2.5）为471 × 12</p><p><em>注意：471是怎么得到的？首先每个月有480个小时，只需要9个小时形成一组来预测第是个小时；举例来看：1-9是一组，预测10；2-10是一组来预测11；以此类推，可以得到471-479是最后一组，预测480</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.empty([<span class="number">12</span> * <span class="number">471</span>, <span class="number">18</span> * <span class="number">9</span>], dtype = float)</span><br><span class="line">y = np.empty([<span class="number">12</span> * <span class="number">471</span>, <span class="number">1</span>], dtype = float)</span><br><span class="line"><span class="keyword">for</span> month <span class="keyword">in</span> range(<span class="number">12</span>):</span><br><span class="line">    <span class="keyword">for</span> day <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        <span class="keyword">for</span> hour <span class="keyword">in</span> range(<span class="number">24</span>):</span><br><span class="line">            <span class="keyword">if</span> day == <span class="number">19</span> <span class="keyword">and</span> hour &gt; <span class="number">14</span>:</span><br><span class="line">                <span class="comment">#执行下个月的数据</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            x[month * <span class="number">471</span> + day * <span class="number">24</span> + hour, :] = month_data[month][:,day * <span class="number">24</span> + hour : day * <span class="number">24</span> + hour + <span class="number">9</span>].reshape(<span class="number">1</span>, <span class="number">-1</span>) <span class="comment">#vector dim:18*9 (9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9)</span></span><br><span class="line">            y[month * <span class="number">471</span> + day * <span class="number">24</span> + hour, <span class="number">0</span>] = month_data[month][<span class="number">9</span>, day * <span class="number">24</span> + hour + <span class="number">9</span>] <span class="comment">#value</span></span><br><span class="line">print(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><pre><code>[[14.  14.  14.  ...  2.   2.   0.5] [14.  14.  13.  ...  2.   0.5  0.3] [14.  13.  12.  ...  0.5  0.3  0.8] ... [17.  18.  19.  ...  1.1  1.4  1.3] [18.  19.  18.  ...  1.4  1.3  1.6] [19.  18.  17.  ...  1.3  1.6  1.8]][[30.] [41.] [44.] ... [17.] [24.] [29.]]</code></pre><h1 id="标准化Normalize"><a href="#标准化Normalize" class="headerlink" title="标准化Normalize"></a>标准化Normalize</h1><p>标准化方法有好几种，可参考下面找个博客，本文的标准化方法是Z-score方法<br><a href="https://www.cnblogs.com/lvdongjie/p/11349701.html">https://www.cnblogs.com/lvdongjie/p/11349701.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mean_x = np.mean(x, axis = <span class="number">0</span>) <span class="comment">#18 * 9 </span></span><br><span class="line">std_x = np.std(x, axis = <span class="number">0</span>) <span class="comment">#18 * 9 </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)): <span class="comment">#12 * 471</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(x[<span class="number">0</span>])): <span class="comment">#18 * 9 </span></span><br><span class="line">        <span class="keyword">if</span> std_x[j] != <span class="number">0</span>:</span><br><span class="line">            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]</span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>array([[-1.35825331, -1.35883937, -1.359222  , ...,  0.26650729,         0.2656797 , -1.14082131],       [-1.35825331, -1.35883937, -1.51819928, ...,  0.26650729,        -1.13963133, -1.32832904],       [-1.35825331, -1.51789368, -1.67717656, ..., -1.13923451,        -1.32700613, -0.85955971],       ...,       [-0.88092053, -0.72262212, -0.56433559, ..., -0.57693779,        -0.29644471, -0.39079039],       [-0.7218096 , -0.56356781, -0.72331287, ..., -0.29578943,        -0.39013211, -0.1095288 ],       [-0.56269867, -0.72262212, -0.88229015, ..., -0.38950555,        -0.10906991,  0.07797893]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#划分训练集和测试集，train_set 用来训练， validation_set用来验证结果</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">x_train_set = x[: math.floor(len(x) * <span class="number">0.8</span>), :]</span><br><span class="line">y_train_set = y[: math.floor(len(y) * <span class="number">0.8</span>), :]</span><br><span class="line">x_validation = x[math.floor(len(x) * <span class="number">0.8</span>):, :]</span><br><span class="line">y_validation = y[math.floor(len(y) * <span class="number">0.8</span>):, :]</span><br><span class="line">print(x_train_set)</span><br><span class="line">print(y_train_set)</span><br><span class="line">print(x_validation)</span><br><span class="line">print(y_validation)</span><br><span class="line">print(len(x_train_set))</span><br><span class="line">print(len(y_train_set))</span><br><span class="line">print(len(x_validation))</span><br><span class="line">print(len(y_validation))</span><br></pre></td></tr></table></figure><h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">dim = <span class="number">18</span> * <span class="number">9</span> + <span class="number">1</span></span><br><span class="line">w = np.zeros([dim, <span class="number">1</span>])</span><br><span class="line">x = np.concatenate((np.ones([<span class="number">12</span> * <span class="number">471</span>, <span class="number">1</span>]), x), axis = <span class="number">1</span>).astype(float)</span><br><span class="line">learning_rate = <span class="number">100</span></span><br><span class="line">iter_time = <span class="number">1000</span></span><br><span class="line">adagrad = np.zeros([dim, <span class="number">1</span>])</span><br><span class="line">eps = <span class="number">0.0000000001</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(iter_time):</span><br><span class="line">    loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, <span class="number">2</span>))/<span class="number">471</span>/<span class="number">12</span>)<span class="comment">#rmse</span></span><br><span class="line">    <span class="keyword">if</span>(t%<span class="number">100</span>==<span class="number">0</span>):</span><br><span class="line">        print(str(t) + <span class="string">&quot;:&quot;</span> + str(loss))</span><br><span class="line">    gradient = <span class="number">2</span> * np.dot(x.transpose(), np.dot(x, w) - y) <span class="comment">#dim*1</span></span><br><span class="line">    adagrad += gradient ** <span class="number">2</span></span><br><span class="line">    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)</span><br><span class="line">np.save(<span class="string">&#x27;myweight.npy&#x27;</span>, w)</span><br><span class="line">w</span><br></pre></td></tr></table></figure><pre><code>0:27.071214829194115100:33.78905859777455200:19.913751298197102300:13.531068193689693400:10.64546615844617500:9.277353455475062600:8.518042045956497700:8.014061987588418800:7.636756824775688900:7.336563740371121</code></pre><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">testdata = pd.read_csv(<span class="string">&#x27;./hw1_test.csv&#x27;</span>, header = <span class="literal">None</span>, encoding = <span class="string">&#x27;big5&#x27;</span>)</span><br><span class="line">test_data = testdata.iloc[:, <span class="number">2</span>:]</span><br><span class="line">test_data[test_data == <span class="string">&#x27;NR&#x27;</span>] = <span class="number">0</span></span><br><span class="line">test_data = test_data.to_numpy()</span><br><span class="line">test_x = np.empty([<span class="number">240</span>, <span class="number">18</span>*<span class="number">9</span>], dtype = float)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">240</span>):</span><br><span class="line">    test_x[i, :] = test_data[<span class="number">18</span> * i: <span class="number">18</span>* (i + <span class="number">1</span>), :].reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(test_x)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(test_x[<span class="number">0</span>])):</span><br><span class="line">        <span class="keyword">if</span> std_x[j] != <span class="number">0</span>:</span><br><span class="line">            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]</span><br><span class="line">test_x = np.concatenate((np.ones([<span class="number">240</span>, <span class="number">1</span>]), test_x), axis = <span class="number">1</span>).astype(float)</span><br><span class="line">test_x</span><br></pre></td></tr></table></figure><pre><code>array([[ 1.        , -0.24447681, -0.24545919, ..., -0.67065391,        -1.04594393,  0.07797893],       [ 1.        , -1.35825331, -1.51789368, ...,  0.17279117,        -0.10906991, -0.48454426],       [ 1.        ,  1.5057434 ,  1.34508393, ..., -1.32666675,        -1.04594393, -0.57829812],       ...,       [ 1.        ,  0.3919669 ,  0.54981237, ...,  0.26650729,        -0.20275731,  1.20302531],       [ 1.        , -1.8355861 , -1.8360023 , ..., -1.04551839,        -1.13963133, -1.14082131],       [ 1.        , -1.35825331, -1.35883937, ...,  2.98427476,         3.26367657,  1.76554849]])</code></pre><h1 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w = np.load(<span class="string">&#x27;myweight.npy&#x27;</span>)</span><br><span class="line">ans_y = np.dot(test_x, w)</span><br><span class="line">ans_y</span><br></pre></td></tr></table></figure><h1 id="保存结果到csv"><a href="#保存结果到csv" class="headerlink" title="保存结果到csv"></a>保存结果到csv</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;my_submit.csv&#x27;</span>, mode=<span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> submit_file:</span><br><span class="line">    csv_writer = csv.writer(submit_file)</span><br><span class="line">    header = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    print(header)</span><br><span class="line">    csv_writer.writerow(header)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">240</span>):</span><br><span class="line">        row = [<span class="string">&#x27;id_&#x27;</span> + str(i), ans_y[i][<span class="number">0</span>]]</span><br><span class="line">        csv_writer.writerow(row)</span><br><span class="line">        print(row)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020年10月17日-10月25日</title>
      <link href="2020/10/17/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%9710%E6%9C%8817%E6%97%A5-10%E6%9C%8825%E6%97%A5/"/>
      <url>2020/10/17/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%9710%E6%9C%8817%E6%97%A5-10%E6%9C%8825%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<blockquote><p>此页面用于记录每日学习情况，用来监督自己，同时把学习资源放在此处方便日后回顾。</p></blockquote><h1 id="2020年10月25日"><a href="#2020年10月25日" class="headerlink" title="2020年10月25日"></a>2020年10月25日</h1><p>写一门课的报告，感觉还是效率太低，不应该花费那么多时间来做这件事。</p><h1 id="2020年10月24日"><a href="#2020年10月24日" class="headerlink" title="2020年10月24日"></a>2020年10月24日</h1><p>今天在配置pytorch环境，弄了一天也没有搞定，还卸载两次anaconda。</p><p>真可谓是：一杯茶、一包烟、一个环境配一天！</p><p>组里的小伙伴过生日，偷偷给他买一个蛋糕，大大的惊喜！</p><p>1024节日快乐！</p><h1 id="2020年10月23日"><a href="#2020年10月23日" class="headerlink" title="2020年10月23日"></a>2020年10月23日</h1><p>今天课最多，下午打球，晚上回实验室学习。</p><p>多运动挺好的！</p><h1 id="2020年10月22日"><a href="#2020年10月22日" class="headerlink" title="2020年10月22日"></a>2020年10月22日</h1><ul><li><input checked disabled type="checkbox"> 《JavaScript前端开发指南（高鹏）》：函数、数组、对象、类、JSON、BOM</li><li><input checked disabled type="checkbox"> 机器学习视频：P13</li><li><input checked disabled type="checkbox"> 看论文</li></ul><h1 id="2020年10月21日"><a href="#2020年10月21日" class="headerlink" title="2020年10月21日"></a>2020年10月21日</h1><p>李宏毅机器学习作业2：classification，作业已经发布在博客中；</p><p>机器学习视频P12、P13</p><h1 id="2020年10月20日"><a href="#2020年10月20日" class="headerlink" title="2020年10月20日"></a>2020年10月20日</h1><p>机器学习视频：P11以及作业二（明天做完）</p><p>最近学习开始慢慢进入了状态，也变得很有规律了，要保持，不过临近期中，要完成一些课程报告了。</p><h1 id="2020年10月19日"><a href="#2020年10月19日" class="headerlink" title="2020年10月19日"></a>2020年10月19日</h1><h2 id="李宏毅机器学习作业一：Regression"><a href="#李宏毅机器学习作业一：Regression" class="headerlink" title="李宏毅机器学习作业一：Regression"></a>李宏毅机器学习作业一：Regression</h2><p>参考：<a href="https://blog.csdn.net/weixin_42447868/article/details/105261672">https://blog.csdn.net/weixin_42447868/article/details/105261672</a></p><p><a href="https://housanduo123.github.io/2020/10/19/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E6%9D%8E%E5%AE%8F%E6%AF%852020spring%EF%BC%89%E4%BD%9C%E4%B8%9A1%EF%BC%9ARegression/">作业链接</a></p><p>机器学习视频：P4、P5、P6、P7、P10</p><h1 id="2020年10月18日、"><a href="#2020年10月18日、" class="headerlink" title="2020年10月18日、"></a>2020年10月18日、</h1><h2 id="多元线性回归算法"><a href="#多元线性回归算法" class="headerlink" title="多元线性回归算法"></a>多元线性回归算法</h2><p><a href="https://blog.csdn.net/weixin_46072771/article/details/104875456">https://blog.csdn.net/weixin_46072771/article/details/104875456</a></p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame, Series</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure><h3 id="封装好的回归算法"><a href="#封装好的回归算法" class="headerlink" title="封装好的回归算法"></a>封装好的回归算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.coef_ = <span class="literal">None</span>    <span class="comment">#系数</span></span><br><span class="line">        self.interception_ = <span class="literal">None</span>  <span class="comment">#截距</span></span><br><span class="line">        self._theta = <span class="literal">None</span>   <span class="comment">#回归系数矩阵</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_normal</span>(<span class="params">self, x_train, y_train</span>):</span></span><br><span class="line">        <span class="comment">#判断数据集的行数是否相等，如果相等就继续，否则异常报错</span></span><br><span class="line">        <span class="keyword">assert</span> x_train.shape[<span class="number">0</span>] == y_train.shape[<span class="number">0</span>], <span class="string">&quot;数据集有问题&quot;</span></span><br><span class="line">        </span><br><span class="line">        x_b = self._data_arrange(x_train)</span><br><span class="line">        self._theta = np.linalg.inv(x_b.T.dot(x_b)).dot(x_b.T).dot(y_train)</span><br><span class="line">        self.interception_ = self._theta[<span class="number">0</span>]</span><br><span class="line">        self.coef_ = self._theta[<span class="number">1</span>:]</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_data_arrange</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        <span class="comment">#数据处理</span></span><br><span class="line">        <span class="keyword">return</span> np.hstack([np.ones((len(data), <span class="number">1</span>)), data]) </span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_test</span>):</span></span><br><span class="line">        x_predict = self._data_arrange(x_test)</span><br><span class="line">        <span class="keyword">return</span> x_predict.dot(self._theta)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, x_test, y_test</span>):</span></span><br><span class="line">        y_predict = self.predict(x_test)</span><br><span class="line">        mse = np.sum((y_predict - y_test)**<span class="number">2</span>) / len(y_test)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - mse / np.var(y_test)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;多元线性回归&quot;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">boston = datasets.load_boston()</span><br><span class="line"></span><br><span class="line">x = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line"></span><br><span class="line">x = x[y&lt;<span class="number">50.0</span>]</span><br><span class="line">y = y[y&lt;<span class="number">50.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#分出训练集和测试集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = <span class="number">0.25</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LR = LinearRegression()</span><br><span class="line">LR.fit_normal(x_train, y_train)</span><br><span class="line">print(LR.coef_)</span><br><span class="line">print(LR.interception_)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>[-1.00264809e-01  2.90685614e-02 -6.96864490e-02  9.01738567e-02 -1.28455530e+01  3.69111172e+00 -2.70338505e-02 -1.33459106e+00  2.19642211e-01 -1.19179332e-02 -8.95809519e-01  7.71167971e-03 -3.48130575e-01]34.60682029779116</code></pre><h2 id="多元回归系数矩阵"><a href="#多元回归系数矩阵" class="headerlink" title="多元回归系数矩阵"></a>多元回归系数矩阵</h2><p><a href="https://zhuanlan.zhihu.com/p/48541799">https://zhuanlan.zhihu.com/p/48541799</a></p><h2 id="最小二乘法线性回归：矩阵视角"><a href="#最小二乘法线性回归：矩阵视角" class="headerlink" title="最小二乘法线性回归：矩阵视角"></a>最小二乘法线性回归：矩阵视角</h2><p><a href="https://zhuanlan.zhihu.com/p/33899560">https://zhuanlan.zhihu.com/p/33899560</a></p><h2 id="Git安装、使用"><a href="#Git安装、使用" class="headerlink" title="Git安装、使用"></a>Git安装、使用</h2><p><a href="https://backlog.com/git-tutorial/cn/intro/intro2_1.html">https://backlog.com/git-tutorial/cn/intro/intro2_1.html</a></p><p>可以直接参考找个教程</p><h2 id="OpenCV-VisualStudio环境配置"><a href="#OpenCV-VisualStudio环境配置" class="headerlink" title="OpenCV+VisualStudio环境配置"></a>OpenCV+VisualStudio环境配置</h2><p>弄了好久还是没有成功，先把JavaScript学习完，过几天再弄吧！</p><h2 id="心语"><a href="#心语" class="headerlink" title="心语"></a>心语</h2><p>好久没有运动，昨天回去的时候跑了几圈，今天全身酸痛，精神一点都不好，调整状态。</p><h1 id="2020年10月17日"><a href="#2020年10月17日" class="headerlink" title="2020年10月17日"></a>2020年10月17日</h1><ul><li>python读取写入文件等操作；<a href="https://zhuanlan.zhihu.com/p/40937189">https://zhuanlan.zhihu.com/p/40937189</a></li><li>通过sklearn调用linearregression算法</li><li>手动实现一元线性回归算法及其算法的评估</li></ul><p>过程如下，代码是自己按照教程重写一遍，略有改动，原文链接也在。图片没有插入进来。</p><h2 id="pandas读取文件"><a href="#pandas读取文件" class="headerlink" title="pandas读取文件"></a>pandas读取文件</h2><h3 id="读取txt文件"><a href="#读取txt文件" class="headerlink" title="读取txt文件"></a>读取txt文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;employee_birthday.txt&#x27;</span>) <span class="keyword">as</span> csv_file:</span><br><span class="line">    csv_reader = csv.reader(csv_file, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    line_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> csv_reader:</span><br><span class="line">        <span class="keyword">if</span> line_count == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">f&#x27;Column names are <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(row)&#125;</span>&#x27;</span>)</span><br><span class="line">            line_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">f&#x27;\t<span class="subst">&#123;row[<span class="number">0</span>]&#125;</span> works in the <span class="subst">&#123;row[<span class="number">1</span>]&#125;</span> department, and was born in <span class="subst">&#123;row[<span class="number">2</span>]&#125;</span>.&#x27;</span>)</span><br><span class="line">            line_count += <span class="number">1</span></span><br><span class="line">    print(<span class="string">f&#x27;Processed <span class="subst">&#123;line_count&#125;</span> lines.&#x27;</span>) </span><br></pre></td></tr></table></figure><pre><code>Column names are name, department, birthday month    John Smith works in the Accounting department, and was born in November.    Erica Meyers works in the IT department, and was born in March.Processed 3 lines.</code></pre><h3 id="将csv文件读入字典"><a href="#将csv文件读入字典" class="headerlink" title="将csv文件读入字典"></a>将csv文件读入字典</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;employee_birthday.txt&#x27;</span>, mode =<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> csv_file:</span><br><span class="line">    csv_reader = csv.DictReader(csv_file)</span><br><span class="line">    line_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> csv_reader:</span><br><span class="line">        <span class="keyword">if</span> line_count == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">f&#x27;Column names are <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(row)&#125;</span>&#x27;</span>)</span><br><span class="line">            line_count += <span class="number">1</span></span><br><span class="line">        print(<span class="string">f&#x27;\t<span class="subst">&#123;row[<span class="string">&quot;name&quot;</span>]&#125;</span> works in the <span class="subst">&#123;row[<span class="string">&quot;department&quot;</span>]&#125;</span> department, and was born in <span class="subst">&#123;row[<span class="string">&quot;birthday month&quot;</span>]&#125;</span>&quot;.&#x27;</span>)</span><br><span class="line">        <span class="comment">#print(f&#x27;\t&#123;row[&quot;name&quot;]&#125; works in the &#123;row[&quot;department&quot;]&#125; department, and was born in &#123;row[&quot;birthday month&quot;]&#125;.&#x27;)</span></span><br><span class="line">        line_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;Preocessed <span class="subst">&#123;line_count&#125;</span> lines.&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Column names are name, department, birthday month    John Smith works in the Accounting department, and was born in November&quot;.    Erica Meyers works in the IT department, and was born in March&quot;.Preocessed 3 lines.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;employee_birthday.txt&#x27;</span>, mode=<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> csv_file:</span><br><span class="line">    csv_reader = csv.DictReader(csv_file)</span><br><span class="line">    line_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> csv_reader:</span><br><span class="line">        <span class="keyword">if</span> line_count == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">f&#x27;Column names are <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(row)&#125;</span>&#x27;</span>)</span><br><span class="line">            line_count += <span class="number">1</span></span><br><span class="line">        print(<span class="string">f&#x27;\t<span class="subst">&#123;row[<span class="string">&quot;name&quot;</span>]&#125;</span> works in the <span class="subst">&#123;row[<span class="string">&quot;department&quot;</span>]&#125;</span> department, and was born in <span class="subst">&#123;row[<span class="string">&quot;birthday month&quot;</span>]&#125;</span>.&#x27;</span>)</span><br><span class="line">        line_count += <span class="number">1</span></span><br><span class="line">    print(<span class="string">f&#x27;Processed <span class="subst">&#123;line_count&#125;</span> lines.&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Column names are name, department, birthday month    &#123;row[&quot;name&quot;]&#125; works in the &#123;row[&quot;department&quot;]&#125; department, and was born in &#123;row[&quot;birthday month&quot;]&#125;.    &#123;row[&quot;name&quot;]&#125; works in the &#123;row[&quot;department&quot;]&#125; department, and was born in &#123;row[&quot;birthday month&quot;]&#125;.Processed 3 lines.</code></pre><h3 id="使用csv写入csv文件"><a href="#使用csv写入csv文件" class="headerlink" title="使用csv写入csv文件"></a>使用csv写入csv文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;employee_file.csv&#x27;</span>, mode = <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> employee_file:</span><br><span class="line">    employee_writer = csv.writer(employee_file, delimiter = <span class="string">&#x27;,&#x27;</span>, quotechar = <span class="string">&#x27;&quot;&#x27;</span>, quoting = csv.QUOTE_MINIMAL)</span><br><span class="line">    employee_writer.writerow([<span class="string">&#x27;John Smith&#x27;</span>, <span class="string">&#x27;Acounting&#x27;</span>, <span class="string">&#x27;November&#x27;</span>])</span><br><span class="line">    employee_writer.writerow([<span class="string">&#x27;Erica Meyers&#x27;</span>, <span class="string">&#x27;IT&#x27;</span>, <span class="string">&#x27;March&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用csv把字典写入csv文件"><a href="#使用csv把字典写入csv文件" class="headerlink" title="使用csv把字典写入csv文件"></a>使用csv把字典写入csv文件</h3><p>写入的时候会有空行，要加入newline=‘’,这样每行之后的空行就会消失</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;employee_file2.csv&#x27;</span>, mode=<span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> csv_file:</span><br><span class="line">    fieldnames = [<span class="string">&#x27;emp_name&#x27;</span>, <span class="string">&#x27;dept&#x27;</span>, <span class="string">&#x27;birth_month&#x27;</span>]</span><br><span class="line">    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)</span><br><span class="line">    writer.writeheader()</span><br><span class="line">    writer.writerow(&#123;<span class="string">&#x27;emp_name&#x27;</span>:<span class="string">&#x27;John Smith&#x27;</span>, <span class="string">&#x27;dept&#x27;</span>:<span class="string">&#x27;Acounting&#x27;</span>, <span class="string">&#x27;birth_month&#x27;</span>:<span class="string">&#x27;November&#x27;</span>&#125;)</span><br><span class="line">    writer.writerow(&#123;<span class="string">&#x27;emp_name&#x27;</span>:<span class="string">&#x27;Erica Meyers&#x27;</span>, <span class="string">&#x27;dept&#x27;</span>:<span class="string">&#x27;IT&#x27;</span>, <span class="string">&#x27;birth_month&#x27;</span>:<span class="string">&#x27;March&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="使用pandas读取csv文件"><a href="#使用pandas读取csv文件" class="headerlink" title="使用pandas读取csv文件"></a>使用pandas读取csv文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把txt读入到csv</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">fh = open(<span class="string">r&#x27;hrdata.csv&#x27;</span>,mode=<span class="string">&#x27;w&#x27;</span>,newline=<span class="string">&quot;&quot;</span>)</span><br><span class="line">writer = csv.writer(fh)</span><br><span class="line">csvRow = []</span><br><span class="line"></span><br><span class="line">data = open(<span class="string">r&#x27;hrdata.txt&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> data:</span><br><span class="line">    csvRow = line.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    writer.writerow(csvRow)</span><br><span class="line">fh.close()</span><br><span class="line">data.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">df = pandas.read_csv(<span class="string">&#x27;hrdata.csv&#x27;</span>)</span><br><span class="line">print(df)</span><br><span class="line">print(type(df[<span class="string">&#x27;Hire Date&#x27;</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>             Name Hire Date   Salary  Sick Days remaining\n0  Graham Chapman  03/15/14  50000.0                     101     John Cleese  06/01/15  65000.0                      82       Eric Idle  05/12/14  45000.0                     103     Terry Jones  11/01/13  70000.0                      34   Terry Gilliam  08/12/14  48000.0                      75   Michael Palin  05/23/13  66000.0                      8&lt;class &#39;str&#39;&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把Name作为索引</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df2 = pd.read_csv(<span class="string">&#x27;hrdata.csv&#x27;</span>, index_col = <span class="string">&#x27;Name&#x27;</span>)</span><br><span class="line">print(df2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>               Hire Date   Salary  Sick Days remaining\nName                                                    Graham Chapman  03/15/14  50000.0                     10John Cleese     06/01/15  65000.0                      8Eric Idle       05/12/14  45000.0                     10Terry Jones     11/01/13  70000.0                      3Terry Gilliam   08/12/14  48000.0                      7Michael Palin   05/23/13  66000.0                      8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把Hire Date作为日期使用</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df3 = pd.read_csv(<span class="string">&#x27;hrdata.csv&#x27;</span>, index_col = <span class="string">&#x27;Name&#x27;</span>, parse_dates=[<span class="string">&#x27;Hire Date&#x27;</span>])</span><br><span class="line">print(df3)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>                Hire Date   Salary  Sick Days remaining\nName                                                     Graham Chapman 2014-03-15  50000.0                     10John Cleese    2015-06-01  65000.0                      8Eric Idle      2014-05-12  45000.0                     10Terry Jones    2013-11-01  70000.0                      3Terry Gilliam  2014-08-12  48000.0                      7Michael Palin  2013-05-23  66000.0                      8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一行没有列名, header=0为了忽略列名</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df4 = pd.read_csv(<span class="string">&#x27;hrdata.csv&#x27;</span>,</span><br><span class="line">                 index_col=<span class="string">&#x27;Employee&#x27;</span>,</span><br><span class="line">                 parse_dates=[<span class="string">&#x27;Hired&#x27;</span>],</span><br><span class="line">                 header = <span class="number">0</span>,</span><br><span class="line">                 names = [<span class="string">&#x27;Employee&#x27;</span>, <span class="string">&#x27;Hired&#x27;</span>, <span class="string">&#x27;Salary&#x27;</span>, <span class="string">&#x27;Sick Days&#x27;</span>])</span><br><span class="line">print(df4)</span><br><span class="line">df4.to_csv(<span class="string">&#x27;hrdata_modified.csv&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>                    Hired   Salary  Sick DaysEmployee                                     Graham Chapman 2014-03-15  50000.0         10John Cleese    2015-06-01  65000.0          8Eric Idle      2014-05-12  45000.0         10Terry Jones    2013-11-01  70000.0          3Terry Gilliam  2014-08-12  48000.0          7Michael Palin  2013-05-23  66000.0          8</code></pre><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="简单线性回归"><a href="#简单线性回归" class="headerlink" title="简单线性回归"></a>简单线性回归</h3><p><a href="https://blog.csdn.net/weixin_40014576/article/details/79918819">https://blog.csdn.net/weixin_40014576/article/details/79918819</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame, Series</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment">#from sklearn.cross_validation import train_test_split</span></span><br><span class="line"><span class="comment">#from sklearn.liner_model import LinearRegression</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建数据集</span></span><br><span class="line">examDict  = &#123;<span class="string">&#x27;学习时间&#x27;</span>:[<span class="number">0.50</span>,<span class="number">0.75</span>,<span class="number">1.00</span>,<span class="number">1.25</span>,<span class="number">1.50</span>,<span class="number">1.75</span>,<span class="number">1.75</span>,</span><br><span class="line">                     <span class="number">2.00</span>,<span class="number">2.25</span>,<span class="number">2.50</span>,<span class="number">2.75</span>,<span class="number">3.00</span>,<span class="number">3.25</span>,<span class="number">3.50</span>,<span class="number">4.00</span>,<span class="number">4.25</span>,<span class="number">4.50</span>,<span class="number">4.75</span>,<span class="number">5.00</span>,<span class="number">5.50</span>],</span><br><span class="line">             <span class="string">&#x27;分数&#x27;</span>:[<span class="number">10</span>,<span class="number">22</span>,<span class="number">13</span>,<span class="number">43</span>,<span class="number">20</span>,<span class="number">22</span>,<span class="number">33</span>,<span class="number">50</span>,<span class="number">62</span>,</span><br><span class="line">                   <span class="number">48</span>,<span class="number">55</span>,<span class="number">75</span>,<span class="number">62</span>,<span class="number">73</span>,<span class="number">81</span>,<span class="number">76</span>,<span class="number">64</span>,<span class="number">82</span>,<span class="number">90</span>,<span class="number">93</span>]&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#转换为DataFrame的数据格式</span></span><br><span class="line">exam = DataFrame(examDict)</span><br><span class="line">print(exam)</span><br></pre></td></tr></table></figure><pre><code>    学习时间  分数0   0.50  101   0.75  222   1.00  133   1.25  434   1.50  205   1.75  226   1.75  337   2.00  508   2.25  629   2.50  4810  2.75  5511  3.00  7512  3.25  6213  3.50  7314  4.00  8115  4.25  7616  4.50  6417  4.75  8218  5.00  9019  5.50  93</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制散点图</span></span><br><span class="line">plt.scatter(exam.分数,exam.学习时间, color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&quot;Exam Data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加图的标签（x轴， y轴）</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Hours&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#两者的相关性系数</span></span><br><span class="line">rDf = exam.corr()</span><br><span class="line">print(rDf)</span><br></pre></td></tr></table></figure><pre><code>          学习时间        分数学习时间  1.000000  0.923985分数    0.923985  1.000000</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将原始数据分为训练集和数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(exam.学习时间, exam.分数, train_size=<span class="number">0.7</span>)</span><br><span class="line"><span class="comment">#x_train, x_test分别为训练数据标签、测试数据标签， train_size为训练数据的占比</span></span><br><span class="line">print(<span class="string">&quot;原始数据特征：&quot;</span>, exam.学习时间.shape,</span><br><span class="line">     <span class="string">&quot;,训练数据特征：&quot;</span>, x_train.shape,</span><br><span class="line">     <span class="string">&quot;,测试数据特征：&quot;</span>, x_test.shape)</span><br><span class="line">print(<span class="string">&quot;原始数据标签：&quot;</span>, exam.分数.shape,</span><br><span class="line">     <span class="string">&quot;,训练数据特征：&quot;</span>, y_train.shape,</span><br><span class="line">     <span class="string">&quot;,测试数据特征: &quot;</span>, y_test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#散点图</span></span><br><span class="line">plt.scatter(x_train, y_train, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&quot;train data&quot;</span>)</span><br><span class="line">plt.scatter(x_test, y_test, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&quot;test data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加图标标签</span></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Hours&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;pass&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.savefig(<span class="string">&quot;tests.jpg&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>原始数据特征： (20,) ,训练数据特征： (14,) ,测试数据特征： (6,)原始数据标签： (20,) ,训练数据特征： (14,) ,测试数据特征:  (6,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用LinearRegression</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">x_train = x_train.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">y_train = y_train.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获得截距、回归系数</span></span><br><span class="line">a = model.intercept_</span><br><span class="line">b = model.coef_</span><br><span class="line">print(<span class="string">&quot;最佳拟合线：截距:&quot;</span>, a, <span class="string">&quot;,回归系数:&quot;</span>, b)</span><br></pre></td></tr></table></figure><pre><code>最佳拟合线：截距: [6.96116134] ,回归系数: [[16.98153572]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练数据的预测值</span></span><br><span class="line">y_train_pred = model.predict(x_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制最佳拟合线</span></span><br><span class="line">plt.plot(x_train, y_train_pred, color=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">4</span>, label=<span class="string">&quot;BestLine&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试数据散点图</span></span><br><span class="line">plt.scatter(x_test, y_test, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&quot;TestData&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加图标签</span></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Hours&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.savefig(<span class="string">&quot;lines.jpg&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试数据得到的模型分数</span></span><br><span class="line">x_test = x_test.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">y_test = y_test.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">score = model.score(x_test, y_test)</span><br><span class="line">print(<span class="string">&quot;score=&quot;</span>, score)</span><br></pre></td></tr></table></figure><pre><code>score= 0.5830411327857772</code></pre><h3 id="手动实现简单线性回归算法"><a href="#手动实现简单线性回归算法" class="headerlink" title="手动实现简单线性回归算法"></a>手动实现简单线性回归算法</h3><p><a href="https://blog.csdn.net/weixin_46072771/article/details/104875456">https://blog.csdn.net/weixin_46072771/article/details/104875456</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame, Series</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封装自己的简单线性回归</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLinearRegression</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.a = <span class="literal">None</span></span><br><span class="line">        self.b = <span class="literal">None</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x_train, y_train</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        训练参数</span></span><br><span class="line"><span class="string">        :param x_train:属性数据集</span></span><br><span class="line"><span class="string">        :param y_train:特征数据集</span></span><br><span class="line"><span class="string">        :return: a回归系数， b截距</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> x_train.ndim == <span class="number">1</span>,<span class="string">&quot;一元线性回归只能有一个属性&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> len(x_train) == len(y_train), <span class="string">&quot;属性-标签一一对应&quot;</span></span><br><span class="line">        </span><br><span class="line">        x_mean = np.mean(x_train)</span><br><span class="line">        y_mean = np.mean(y_train)</span><br><span class="line">        </span><br><span class="line">        num = <span class="number">0.0</span></span><br><span class="line">        d = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> zip(x_train, y_train):</span><br><span class="line">            num += (x_i - x_mean) * (y_i - y_mean)</span><br><span class="line">            d += (x_i - x_mean) ** <span class="number">2</span></span><br><span class="line">        <span class="comment"># a代表斜率，b代表截距</span></span><br><span class="line">        self.a = num / d</span><br><span class="line">        self.b = y_mean - self.a * x_mean</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_predict</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        预测一组数据</span></span><br><span class="line"><span class="string">        :param x_predict：预测数据集</span></span><br><span class="line"><span class="string">        :return:预测结果</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> x_predict.ndim == <span class="number">1</span>, <span class="string">&quot;只能有一个属性&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> self.a <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self.b <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, <span class="string">&quot;need use .fit()&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> np.array([self._predict(x) <span class="keyword">for</span> x <span class="keyword">in</span> x_predict])</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_predict</span>(<span class="params">self, x_single</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对单一数据进行线性回归</span></span><br><span class="line"><span class="string">        :param x_single：单一预测数据</span></span><br><span class="line"><span class="string">        :return: 预测结果</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.a * x_single + self.b</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;一元线性规划&quot;</span></span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建数据集</span></span><br><span class="line">examDict  = &#123;<span class="string">&#x27;学习时间&#x27;</span>:[<span class="number">0.50</span>,<span class="number">0.75</span>,<span class="number">1.00</span>,<span class="number">1.25</span>,<span class="number">1.50</span>,<span class="number">1.75</span>,<span class="number">1.75</span>,</span><br><span class="line">                     <span class="number">2.00</span>,<span class="number">2.25</span>,<span class="number">2.50</span>,<span class="number">2.75</span>,<span class="number">3.00</span>,<span class="number">3.25</span>,<span class="number">3.50</span>,<span class="number">4.00</span>,<span class="number">4.25</span>,<span class="number">4.50</span>,<span class="number">4.75</span>,<span class="number">5.00</span>,<span class="number">5.50</span>],</span><br><span class="line">             <span class="string">&#x27;分数&#x27;</span>:[<span class="number">10</span>,<span class="number">22</span>,<span class="number">13</span>,<span class="number">43</span>,<span class="number">20</span>,<span class="number">22</span>,<span class="number">33</span>,<span class="number">50</span>,<span class="number">62</span>,</span><br><span class="line">                   <span class="number">48</span>,<span class="number">55</span>,<span class="number">75</span>,<span class="number">62</span>,<span class="number">73</span>,<span class="number">81</span>,<span class="number">76</span>,<span class="number">64</span>,<span class="number">82</span>,<span class="number">90</span>,<span class="number">93</span>]&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#转换为DataFrame的数据格式</span></span><br><span class="line">exam = DataFrame(examDict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将原始数据分为训练集和数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(exam.学习时间, exam.分数, train_size=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#调用SimpleLinearRegression</span></span><br><span class="line">SLR = SimpleLinearRegression()</span><br><span class="line">SLR.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练数据的预测值</span></span><br><span class="line">y_train_pred = SLR.predict(x_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制最佳拟合线</span></span><br><span class="line">plt.plot(x_train, y_train_pred, color=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">4</span>, label=<span class="string">&quot;BestLine&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试数据散点图</span></span><br><span class="line">plt.scatter(x_test, y_test, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&quot;TestData&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加图标签</span></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Hours&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Text(0, 0.5, &#39;Score&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#预测测试集,并输出测试集以及预测之后的结果</span></span><br><span class="line">y_test_pred = SLR.predict(x_test)</span><br><span class="line">plt.scatter(x_test, y_test, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x_test, y_test_pred, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#预测单个数值</span></span><br><span class="line">y_test_predOne = SLR._predict(<span class="number">3.5</span>)</span><br><span class="line">print(y_test_predOne)</span><br></pre></td></tr></table></figure><pre><code>64.75262597046735</code></pre><h3 id="回归算法评估"><a href="#回归算法评估" class="headerlink" title="回归算法评估"></a>回归算法评估</h3><p><a href="https://blog.csdn.net/zrh_CSDN/article/details/81190221">https://blog.csdn.net/zrh_CSDN/article/details/81190221</a><br>评价方式包括：RMSE均方根误差、MSE均方误差、MAE绝对误差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据处理-以波士顿房价数据中【房间个数-RM】</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">boston = datasets.load_boston()</span><br><span class="line">print(boston.feature_names)</span><br></pre></td></tr></table></figure><pre><code>[&#39;CRIM&#39; &#39;ZN&#39; &#39;INDUS&#39; &#39;CHAS&#39; &#39;NOX&#39; &#39;RM&#39; &#39;AGE&#39; &#39;DIS&#39; &#39;RAD&#39; &#39;TAX&#39; &#39;PTRATIO&#39; &#39;B&#39; &#39;LSTAT&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘制散点图</span></span><br><span class="line">x = boston.data[:, <span class="number">5</span>]</span><br><span class="line">y = boston.target</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#上图中有部分数据报表，超过五十，因此我们进行数据删除</span></span><br><span class="line">x = x[y&lt;<span class="number">50.0</span>]</span><br><span class="line">y = y[y&lt;<span class="number">50.0</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据分为训练集和测试集</span></span><br><span class="line">x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, train_size = <span class="number">0.75</span>)</span><br><span class="line">SLR.fit(x_train2, y_train2)</span><br><span class="line">plt.scatter(x_train2, y_train2)</span><br><span class="line">plt.plot(x_train2, SLR.predict(x_train2), color = <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x23433fbb3a0&gt;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#均方差</span></span><br><span class="line">y_predict2 = SLR.predict(x_test2)</span><br><span class="line">mse_test = np.sum((y_predict2 - y_test2)**<span class="number">2</span>)/len(y_test2)</span><br><span class="line">print(mse_test)</span><br></pre></td></tr></table></figure><pre><code>28.3742090622532</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Learning Log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习（李宏毅2020spring）》学习笔记(持续更新)</title>
      <link href="2020/10/15/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2020/10/15/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p>李宏毅老师：<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">个人主页</a>在这里有上课的课件、课后题目数据集及源码</p><p>课程视频（B站）：<a href="https://www.bilibili.com/video/BV1JE411g7XF?from=search&seid=2314636143203069326">B站</a></p><p>课程笔记：<a href="https://datawhalechina.github.io/leeml-notes/#/">GitHub1</a>、<a href="https://github.com/Sakura-gh/ML-notes">GitHub2</a></p><p>作业说明及范例：<a href="https://github.com/Iallen520/lhy_DL_Hw">GitHub</a></p><p><a href="http://zh.d2l.ai/index.html">动手学深度学习</a>：这本书也不错，理论与实践结合紧密</p><p><a href="http://neuralnetworksanddeeplearning.com/index.html">Neural Networks and Deep Learning</a></p><p><a href="https://blog.csdn.net/u012589040/article/details/106206592?biz_id=102&utm_term=CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-4-106206592&spm=1018.2118.3001.4187">CNN十大经典论文</a></p><p>TensorFlow：<a href="http://c.biancheng.net/view/1911.html">http://c.biancheng.net/view/1911.html</a></p><p>这个也可以参考一下：<a href="https://blog.csdn.net/iteapoy/article/details/105382315">https://blog.csdn.net/iteapoy/article/details/105382315</a></p><h1 id="Learning-Map"><a href="#Learning-Map" class="headerlink" title="Learning Map"></a>Learning Map</h1><img src="/2020/10/15/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png" class title="LearningMap"><h1 id="HomeWork"><a href="#HomeWork" class="headerlink" title="HomeWork"></a>HomeWork</h1><table><thead><tr><th align="center">序号</th><th align="left">任务</th><th align="left">完成情况</th><th align="center">完成时间</th></tr></thead><tbody><tr><td align="center">1</td><td align="left">Linear Regression</td><td align="left"><a href="https://housanduo123.github.io/2020/10/19/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E6%9D%8E%E5%AE%8F%E6%AF%852020spring%EF%BC%89%E4%BD%9C%E4%B8%9A1%EF%BC%9ARegression/">✔Regression</a></td><td align="center">2020/10/19</td></tr><tr><td align="center">2</td><td align="left">Classification</td><td align="left"><a href="https://housanduo123.github.io/2020/10/21/my-hw2-classification/">✔Classification</a></td><td align="center">2020/10/21</td></tr><tr><td align="center">3</td><td align="left">CNN</td><td align="left">待完成</td><td align="center"></td></tr></tbody></table><h1 id="P4-Basic-Concept"><a href="#P4-Basic-Concept" class="headerlink" title="P4 Basic Concept"></a>P4 Basic Concept</h1><p><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">Bias and Variance如何区分理解？</a></p><p><a href="https://segmentfault.com/a/1190000016447144">偏差(Bias)和方差(Variance)——机器学习中的模型选择</a></p><h1 id="P5Gradien-Descent1"><a href="#P5Gradien-Descent1" class="headerlink" title="P5Gradien Descent1"></a>P5Gradien Descent1</h1><h2 id="Tips1：调整学习速率——自适应学习率"><a href="#Tips1：调整学习速率——自适应学习率" class="headerlink" title="Tips1：调整学习速率——自适应学习率"></a>Tips1：调整学习速率——自适应学习率</h2><p>简单而言：随着次数的增加，通过一些因子来减少学习率</p><p>通常来讲，初始点距离最低点会较远，这时我们想要使用较大的学习率；但是更新几次参数之后，就会距离最低点比较近了，如果学习率依然比较大就容易错过最低点，此时就应该通过减小学习率。</p><p>主要介绍了Adagrad算法，但是当距离最低点很近的时候，会存在学习率过慢的问题；</p><h2 id="Tips2：随机梯度下降算法"><a href="#Tips2：随机梯度下降算法" class="headerlink" title="Tips2：随机梯度下降算法"></a>Tips2：随机梯度下降算法</h2><p>常规的梯度下降算法是走一步要处理所有的例子；而随机算法是每走一步就更新一次梯度；</p><h2 id="Tips3：特征缩放"><a href="#Tips3：特征缩放" class="headerlink" title="Tips3：特征缩放"></a>Tips3：特征缩放</h2><p>把特征的规模缩放成相同的或者差不多的，不要差别太大；</p><h1 id="P10-Classification"><a href="#P10-Classification" class="headerlink" title="P10 Classification"></a>P10 Classification</h1><h3 id="分类模型（二分类）"><a href="#分类模型（二分类）" class="headerlink" title="分类模型（二分类）"></a>分类模型（二分类）</h3><p>在function一个函数g（x），如果大于0，就认为是类别1，否则认为类别2。</p><p>损失函数定义可以是，L（f）在训练集预测错误的次数，当然希望错误次数越小越好；</p><h1 id="P11-Logistic-Regression"><a href="#P11-Logistic-Regression" class="headerlink" title="P11 Logistic Regression"></a>P11 Logistic Regression</h1><h1 id="P12-Brief-Introduction-of-Deep-Learning"><a href="#P12-Brief-Introduction-of-Deep-Learning" class="headerlink" title="P12:Brief Introduction of Deep Learning"></a>P12:Brief Introduction of Deep Learning</h1><p><strong>注意，看完P12可以直接跳过去看P15， 然后再看Ｐ13.</strong></p><h2 id="Three-Steps-for-Deep-Learning"><a href="#Three-Steps-for-Deep-Learning" class="headerlink" title="Three Steps for Deep Learning"></a>Three Steps for Deep Learning</h2><h3 id="Step1-Neural-Network"><a href="#Step1-Neural-Network" class="headerlink" title="Step1:Neural Network"></a>Step1:Neural Network</h3><p>神经网络可以有多种不同的连接方式，这样就会产生不同的结构，期间会用到不同的逻辑回归函数，每个逻辑回归函数都有自己的权重和偏差（就是参数)，而神经元的连接方式是可以手动设计的。</p><h4 id="Fully-Connect-Feedforward-Network完全连接前馈神经网络"><a href="#Fully-Connect-Feedforward-Network完全连接前馈神经网络" class="headerlink" title="Fully Connect Feedforward Network完全连接前馈神经网络"></a>Fully Connect Feedforward Network完全连接前馈神经网络</h4><p>信号输入之后，流动方向是单向的，从前一层流向后一层。</p><p>全连接：相连的两层之间两两都由连接；</p><p>前馈：传递方向是从后向前；</p><p>输入层：一层；隐藏层：N层；输出层：一层；</p><h4 id="矩阵计算"><a href="#矩阵计算" class="headerlink" title="矩阵计算"></a>矩阵计算</h4><p>为了降低运算量，我们通过矩阵进行运算，每一层之间都运算一层，并层层嵌套，就相当于是内层函数的结果是外层函数的变量，嵌套多层；</p><h3 id="Step2-Goodness-of-Function"><a href="#Step2-Goodness-of-Function" class="headerlink" title="Step2:Goodness of Function"></a>Step2:Goodness of Function</h3><p>判断一个模型的好坏，和之前在逻辑回归一样，采用cross entropy交叉熵来计算，然后调整参数，让交叉熵越小越好</p><h3 id="Step3：选择最优函数"><a href="#Step3：选择最优函数" class="headerlink" title="Step3：选择最优函数"></a>Step3：选择最优函数</h3><p>通过梯度下降的方法找到最优函数和最好的一组参数，可以参考之前的视频。</p><h1 id="P13：Backpropagation反向传播"><a href="#P13：Backpropagation反向传播" class="headerlink" title="P13：Backpropagation反向传播"></a>P13：Backpropagation反向传播</h1><h2 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h2><p>用来求导的，可以回顾高等数学的微积分，不难</p><h2 id="Forward-Pass-与-Backward-Pass"><a href="#Forward-Pass-与-Backward-Pass" class="headerlink" title="Forward Pass 与 Backward Pass"></a>Forward Pass 与 Backward Pass</h2><p>ForwardPass就是正向求导，BackwardPass就是逆向求导，看着公式推一下就可以了。</p><h1 id="P14Tips-for-Training-DNN"><a href="#P14Tips-for-Training-DNN" class="headerlink" title="P14Tips for Training DNN"></a>P14Tips for Training DNN</h1><h1 id="P15Why-Deep"><a href="#P15Why-Deep" class="headerlink" title="P15Why Deep?"></a>P15Why Deep?</h1><p>从深度-&gt;程序的模块化，可以互相调用相同的模块，把复杂的问题变得简单，随着层次的增加，层次的功能变得更加复杂。</p><h1 id="P17CNN"><a href="#P17CNN" class="headerlink" title="P17CNN"></a>P17CNN</h1><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://easyai.tech/ai-definition/cnn/">https://easyai.tech/ai-definition/cnn/</a></p><p><a href="https://www.cnblogs.com/kongweisi/p/10987870.html">https://www.cnblogs.com/kongweisi/p/10987870.html</a></p><p>CNN解决的问题：第一个是将图像维度降低之后再处理，可以简化处理过程，降维并不会影响结果；第二个是保留图像的特征；</p><h2 id="Input-Layer"><a href="#Input-Layer" class="headerlink" title="Input Layer"></a>Input Layer</h2><p>输入层需要对数据进行预处理操作，常见的是：去均值、归一化、PCA/白化。</p><h2 id="Convolution-Max-Pooling-can-repeat-many-times"><a href="#Convolution-Max-Pooling-can-repeat-many-times" class="headerlink" title="Convolution+Max Pooling(can repeat many times)"></a>Convolution+Max Pooling(can repeat many times)</h2><p>卷积层：通过卷积核来提取原始图像的特征</p><p>池化层：有效降低数据的维度，减少运算量，避免过度拟合</p><h3 id="Convolution（卷积层）"><a href="#Convolution（卷积层）" class="headerlink" title="Convolution（卷积层）"></a>Convolution（卷积层）</h3><p>图像中不同数据窗口的数据和卷积核（Filter)作内积的操作叫做卷积，本质是提取图像不同频段的特征。</p><p>处理黑白照片，就是一个matrix与卷积核求内积；处理彩色照片（相当于是RGB三种颜色叠加的图片，相当于是三个通道Chanel），就是三个Matrix与卷积核求内积，其中卷积核也是三层；</p><img src="/2020/10/15/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/p17-2.gif" class><p>将输入矩阵与卷积核进行内积运算，得到一个新的矩阵。卷积核本质上是一个小规模的矩阵，相当于一个小矩阵在大矩阵上进行移动，移动的步长可以设定，最后得到一个新的矩阵。这样做既可以有效提取特征，还可以解决参数数量太大的问题。</p><p>每一个卷积核相当于一个神经元，可以共享同一个卷积核，称为权值共享。</p><p>步长：卷积核在大矩阵上移动的距离，一般设置为1；</p><p>通道：如果原始数据有多层，那么卷积核也要有相同的层次，例如RGB图片，就是由三层不同颜色组成，</p><h3 id="Pooling（池化层）"><a href="#Pooling（池化层）" class="headerlink" title="Pooling（池化层）"></a>Pooling（池化层）</h3><p>作用是压缩数据，减少参数的数目，其方法很多，一般采用Max Pooling，最大池化，只取最大值。</p><p>注意：卷积层和池化层可以多次重复出现，其作用都是一样的，只是卷积核可以根据需要进行调整。</p><h2 id="Fully-Connected-Feedforward-network"><a href="#Fully-Connected-Feedforward-network" class="headerlink" title="Fully Connected Feedforward network"></a>Fully Connected Feedforward network</h2><p>把多维数据进行Flatten，得到一维数据，进行全连接；</p><p>CNN卷积过程：<a href="https://blog.csdn.net/aaa958099161/article/details/90346899">https://blog.csdn.net/aaa958099161/article/details/90346899</a></p><h1 id="P18-19"><a href="#P18-19" class="headerlink" title="P18-19"></a>P18-19</h1>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Hexo搭建博客并部署到GitHub</title>
      <link href="2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/"/>
      <url>2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>跟着网上的教程摸索了一天时间，终于搭建成功，就赶紧写下这篇博客作为记录。按照网上的教程往往是无法一遍完成的，因为对于新手而言很多配置都没有做，但是教程却忽略了这一点，我会在这篇博客中尽可能详尽说明。</p><h1 id="第一、下载并安装Git和Node-js"><a href="#第一、下载并安装Git和Node-js" class="headerlink" title="第一、下载并安装Git和Node.js"></a>第一、下载并安装Git和Node.js</h1><h2 id="（一）下载安装Git"><a href="#（一）下载安装Git" class="headerlink" title="（一）下载安装Git"></a>（一）下载安装Git</h2><ol><li>下载地址<a href="https://gitforwindows.org/">https://gitforwindows.org/</a></li><li>安装过程</li></ol><p>全程默认安装即可，没有太多需要注意的点。</p><h2 id="（二）下载并安装Node-js"><a href="#（二）下载并安装Node-js" class="headerlink" title="（二）下载并安装Node.js"></a>（二）下载并安装Node.js</h2><ol><li><p>下载地址<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></p><p>有两个版本，分别为LTS和Current版本，下载前者即可。</p><p>安装过程</p></li><li><p>全程默认安装即可，没有太多需要注意的点。</p></li><li><p>对于上述两个步骤，如何判断是否安装成功？</p><p>在安装完成后，打开windows的命令行（Win+R并输入cmd打开），依次输入</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line">git --version</span><br></pre></td></tr></table></figure><p>如果可得到对应的版本号，说明安装正确，如下：</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/1.png" class title="This is an test image"><h1 id="第二、安装Hexo"><a href="#第二、安装Hexo" class="headerlink" title="第二、安装Hexo"></a>第二、安装Hexo</h1><p>Hexo是一个快速、简洁且高效的技术博客框架</p><ol><li><p>通过Git Bash安装Hexo，在任意位置右键鼠标，然后选择“Git Bash”如下图所示</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/2.png" class title="This is an test image"></li><li><p>输入命令npm install -g hexo</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/3.png" class title="This is an test image"></li></ol><h1 id="第三、初始化Hexo"><a href="#第三、初始化Hexo" class="headerlink" title="第三、初始化Hexo"></a>第三、初始化Hexo</h1><p>Hexo的一些基本命令，可参照<a href="https://segmentfault.com/a/1190000002632530">https://segmentfault.com/a/1190000002632530</a></p><ol><li><p>建立个文件夹来存放网站的各种元素</p><p>创建文件夹有两种方式，一种是手动创建，直接右键，然后命名即可（如Blog）；另一种是通过Git创建，在你想要创建的目录下，右键选择“Git Bash”，然后输入（<strong>切记后面所有操作都需要在Blog文件夹右键选择GitBash</strong>）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd Blog</span><br></pre></td></tr></table></figure></li><li><p>初始化Hexo</p><p>在Blog文件夹下右键Git　Bash，并输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><p>之后在Blog文件夹下面会出现如下文件</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/4.png" class title="This is an test image"></li><li><p>修改部分基础配置</p><p>配置文件为“_config.yml”，以记事本方式打开，然后可以针对进行修改一些最基本的配置，只需要修改一下标题，先测试一下即可，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Hexo Configuration</span><br><span class="line"></span><br><span class="line">title: 标题</span><br><span class="line">subtitle: 副标题</span><br><span class="line">description: 描述</span><br><span class="line">keywords: 关键词</span><br><span class="line">author: 自己的名字</span><br><span class="line">language: en</span><br><span class="line">timezone: &#39;&#39;</span><br></pre></td></tr></table></figure><p>注意：一定要注意冒号后面有一个空格，千万不能少</p></li><li><p>在本地浏览博客</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>输入以上两个命令之后，直接复制 <a href="http://localhost:4000到浏览器中，即可打开你的博客，如下（主题不同）：">http://localhost:4000到浏览器中，即可打开你的博客，如下（主题不同）：</a></p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/5.png" class title="This is an test image"></li></ol><p>至此网站已经搭建完成，但是暂时只能在本地浏览，下面会讲到如何部署到GitHub上。</p><h1 id="第四、在Hexo发布文章、更改主题"><a href="#第四、在Hexo发布文章、更改主题" class="headerlink" title="第四、在Hexo发布文章、更改主题"></a>第四、在Hexo发布文章、更改主题</h1><h2 id="1、发布文章"><a href="#1、发布文章" class="headerlink" title="1、发布文章"></a>1、发布文章</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new &quot;我的第一篇博客&quot;</span><br></pre></td></tr></table></figure><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/6.png" class title="This is an test image"><p>在~/Blog/source/_posts文件加下就会出现一个文件，这个文件时markdown格式，需要单独下载Typora<a href="https://typora.io/">https://typora.io/</a> 来编辑博客，这个软件直接下载安装即可。</p><p>启动本地服务器可以进行预览</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g#生成页面</span><br><span class="line">hexo s#启动预览</span><br></pre></td></tr></table></figure><h2 id="2、更改网站的主题"><a href="#2、更改网站的主题" class="headerlink" title="2、更改网站的主题"></a>2、更改网站的主题</h2><p>Hexo官网给我们提供了很多主题，可以直接调用，参照：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p><p>我们以Hiero这个主题为例，进行讲解</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/7.png" class title="This is an test image"><p>点击红色方框的蓝色字体，即可进入Github主页，然后下载压缩包</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/8.png" class title="This is an test image"><p>解压之后把文件复制到~/Blog/themes文件夹之下</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/9.png" class title="This is an test image"><p>修改_config.yml文件（上面讲到了），把theme改为红色方框选中的文件夹名称即可。</p><p>然后输入命令，就可以看到新的主题了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean#清楚缓存</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><h1 id="第五、把Hexo部署到Github"><a href="#第五、把Hexo部署到Github" class="headerlink" title="第五、把Hexo部署到Github"></a>第五、把Hexo部署到Github</h1><p>部署到GitHub是为了可以让大家访问你的博客，而不仅仅是本地浏览</p><ol><li><p>注册并登录GitHub；</p></li><li><p>新建一个仓库，仓库名称为 username.github.io，其中username就是你注册的用户名</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/10.png" class title="This is an test image"></li><li><p>设置用户名和邮箱</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;GitHub的用户名&quot;</span><br><span class="line">git config --global user.email &quot;GitHub的邮箱&quot;</span><br></pre></td></tr></table></figure></li><li><p>创建SSH密匙</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;GitHub的邮箱&quot;</span><br></pre></td></tr></table></figure><p>此时，你的C盘会生成一个.ssh文件，用记事本打开该文件夹下的id_rsa.pub文件，并复制其中的内容</p></li><li><p>在GitHub中New SSH Key</p><p>点击头像&gt;setings&gt;SSH and GPG keys，把刚才复制的内容粘贴到红色方框中即可，Title可写可不写</p><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/11.png" class title="This is an test image"></li><li><p>验证连接是否成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/12.png" class title="This is an test image"></li><li><p>部署Hexo到GitHub Pages</p><ul><li><p>安装hexo-deployer-git</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></li><li><p>修改_config.yml文件，在最下面的Deployment部分</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: 这个地址来自GitHub中我们新建的仓库处，看下图</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><img src="/2020/10/10/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/13.png" class title="This is an test image"></li><li><p>最后重新运行一次即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean </span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>此时就可以通过Github的域名https://用户名.github.io来访问</p></li></ul></li></ol><h1 id="后记：我遇到的问题及解决方案"><a href="#后记：我遇到的问题及解决方案" class="headerlink" title="后记：我遇到的问题及解决方案"></a>后记：我遇到的问题及解决方案</h1><h2 id="1、Hexo与GitHub网页主题不一致"><a href="#1、Hexo与GitHub网页主题不一致" class="headerlink" title="1、Hexo与GitHub网页主题不一致"></a>1、Hexo与GitHub网页主题不一致</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#39;首先清除缓存，然后生成待发布的文件，最后发布&#39;</span><br><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><h2 id="2、在markdown插入的图片无法在网页显示"><a href="#2、在markdown插入的图片无法在网页显示" class="headerlink" title="2、在markdown插入的图片无法在网页显示"></a>2、在markdown插入的图片无法在网页显示</h2><p><a href="https://alexcld.com/2020/08/14/%E8%A7%A3%E5%86%B3Hexo%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/">https://alexcld.com/2020/08/14/%E8%A7%A3%E5%86%B3Hexo%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/</a></p><p>已测试可以使用</p><h2 id="3、更新主题并配置主题"><a href="#3、更新主题并配置主题" class="headerlink" title="3、更新主题并配置主题"></a>3、更新主题并配置主题</h2><p>最复杂的是网站主题的更新及一些配置，首先需要找到一个自己喜欢的主题；其次根据作者的操作文档进行更新一些配置，更新过程中可一边更新一边部署，这样可以防止出bug；</p><h2 id="4、fatal-Could-not-read-from-remote-repository-Please-make-sure-you-have-the-correct-access-rights-and-the-repository-exists"><a href="#4、fatal-Could-not-read-from-remote-repository-Please-make-sure-you-have-the-correct-access-rights-and-the-repository-exists" class="headerlink" title="4、fatal: Could not read from remote repository.Please make sure you have the correct access rights and the repository exists."></a>4、fatal: Could not read from remote repository.Please make sure you have the correct access rights and the repository exists.</h2><p>刚看到之后也很郁闷，经过网上一番搜索之后，只需要把ssh这个步骤重复一次即可，即第五步骤的3-6这个步骤重复，在重复之前需要删除ssh文件夹中的“known_host”文件。</p><p>不过有时候可能是GitHub上传到服务器比较慢，多等一会就可以部署。</p><h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://zhuanlan.zhihu.com/p/60578464">https://zhuanlan.zhihu.com/p/60578464</a></p><p><a href="https://www.jianshu.com/p/189fd945f38f">https://www.jianshu.com/p/189fd945f38f</a></p><p><a href="https://demo.jerryc.me/">https://demo.jerryc.me/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
