<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Recurrent Neural Network循环神经网络 | 三多之路</title><meta name="keywords" content="Deep Learning,RNN"><meta name="author" content="侯三多"><meta name="copyright" content="侯三多"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="RNN综述回顾 Why we need  RNN?对于全连接网络，层与层之间是全连接的，但是每层之间的节点是无连接的，因此全连接网络只能够处理单独的输入（即输入之间没有关联），前一个输入和后一个输入时完全没有关系的，无法处理相互之间关联的数据。 例如，我们输入两句话  arrive BeiJing on November 2nd leave BeiJing on November 2nd  上面这">
<meta property="og:type" content="article">
<meta property="og:title" content="Recurrent Neural Network循环神经网络">
<meta property="og:url" content="http://example.com/2020/10/29/DL-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="三多之路">
<meta property="og:description" content="RNN综述回顾 Why we need  RNN?对于全连接网络，层与层之间是全连接的，但是每层之间的节点是无连接的，因此全连接网络只能够处理单独的输入（即输入之间没有关联），前一个输入和后一个输入时完全没有关系的，无法处理相互之间关联的数据。 例如，我们输入两句话  arrive BeiJing on November 2nd leave BeiJing on November 2nd  上面这">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&h=609&q=90&format=jpg">
<meta property="article:published_time" content="2020-10-29T01:43:27.000Z">
<meta property="article:modified_time" content="2020-11-16T02:39:07.702Z">
<meta property="article:author" content="侯三多">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="RNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&h=609&q=90&format=jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2020/10/29/DL-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: 侯三多","link":"Link: ","source":"Source: 三多之路","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-11-16 10:39:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">19</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Why-we-need-RNN"><span class="toc-number">1.</span> <span class="toc-text">Why we need  RNN?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-Structural-of-RNN"><span class="toc-number">2.</span> <span class="toc-text">The Structural of RNN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RNN%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0"><span class="toc-number">3.</span> <span class="toc-text">RNN优化算法（持续更新)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Long-Short-term-Memory-LSTM"><span class="toc-number">3.1.</span> <span class="toc-text">Long Short-term Memory(LSTM)</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&amp;h=609&amp;q=90&amp;format=jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">三多之路</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Recurrent Neural Network循环神经网络</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-29T01:43:27.000Z" title="Created 2020-10-29 09:43:27">2020-10-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-11-16T02:39:07.702Z" title="Updated 2020-11-16 10:39:07">2020-11-16</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">734</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>2min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.01078.pdf">RNN综述回顾</a></p>
<h1 id="Why-we-need-RNN"><a href="#Why-we-need-RNN" class="headerlink" title="Why we need  RNN?"></a>Why we need  RNN?</h1><p>对于全连接网络，层与层之间是全连接的，但是每层之间的节点是无连接的，因此全连接网络只能够处理单独的输入（即输入之间没有关联），前一个输入和后一个输入时完全没有关系的，无法处理相互之间关联的数据。</p>
<p>例如，我们输入两句话</p>
<blockquote>
<p>arrive BeiJing on November 2nd</p>
<p>leave BeiJing on November 2nd</p>
</blockquote>
<p>上面这两句话后四个单词都是一样的，但是前两个单词决定了这两句话的含义是完全不同的，即前一个单词对当前单词的含义有很大的影响，而全连接网络无法分辨出这种不同，因此我们需要Neral Network具备记忆功能，即在输入下一个单词之前记住前一个单词。</p>
<p>根据上面我们可以知道RNN用来处理遗传相互依赖的数据流，其用途十分广泛，例如文章中的文字、语音里的音频、股票的价格走势……</p>
<h1 id="The-Structural-of-RNN"><a href="#The-Structural-of-RNN" class="headerlink" title="The Structural of RNN"></a>The Structural of RNN</h1><img src="/2020/10/29/DL-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.png" class>

<p>包括四个部分：输入层、隐藏层、循环层、输出层；</p>
<p>输入层经过权重求值之后，在隐藏层经过激活函数得到一个值，这个值进行权重求解之后到输出层的同时，也会保存到循环层存储起来，在下一次有输入的时候，循环层存储的值会再次与输入层的值一起经过激活函数到输出层。</p>
<p>我们举个例子来说明一下：</p>
<blockquote>
<p>假设所有的权重均为1，没有bias；所有的激活函数都是线性的；</p>
<p>输入队列分别是：[1 1] 、[1 1]、[2 2]</p>
<p>当第一次输入[x1 x2]=[1 1]时，隐藏层得到的结果是[2 2]，这个结果会被存储到循环层[a1 a2]=[2 2]，隐藏层进行加权求值，得到输出层结果[4 4]；</p>
<p>当第二次输入[x1 x2]=[1 1]时，隐藏层得到的结果是[6 6]，因为这个结果不仅考虑了输入值，还会考虑循环层的值，这个结果会被存储到循环层[a1 a2]=[6 6]，隐藏层进行加权求值，得到输出层结果[12 12]；</p>
<p>当第三次输入[x1 x2]=[2 2 ]时，隐藏层得到的结果是[16 16]，同样是因为这个结果考虑输入层和循环层，这个结果会被存储到循环层[a1 a2]=[16 16]，隐藏层进行加权求值，得到输出层结果[32 32 ]；</p>
<p>如果对上面的过程还是不理解，可以自己手动带入推演一下即可。</p>
</blockquote>
<p>上面讲解的只是一个层次，深度学习需要多个层次，因此我们需要把许多层连接起来</p>
<img src="/2020/10/29/DL-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.png" class>

<h1 id="RNN优化算法（持续更新"><a href="#RNN优化算法（持续更新" class="headerlink" title="RNN优化算法（持续更新)"></a>RNN优化算法（持续更新)</h1><h2 id="Long-Short-term-Memory-LSTM"><a href="#Long-Short-term-Memory-LSTM" class="headerlink" title="Long Short-term Memory(LSTM)"></a>Long Short-term Memory(LSTM)</h2><p>参考</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/c0fa54dd20f7">https://www.jianshu.com/p/c0fa54dd20f7</a></p>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/RNN/">RNN</a></div><div class="post_share"><div class="social-share" data-image="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&amp;h=609&amp;q=90&amp;format=jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/10/30/DL-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"><img class="prev-cover" src="https://store-images.s-microsoft.com/image/apps.8755.14309757982396439.717bf586-020c-4e5f-9970-26635abeab18.0e591ced-1c02-46b7-a929-0b4f3e984b8a?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Linear Regression线性回归模型</div></div></a></div><div class="next-post pull-right"><a href="/2020/10/28/DL-%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%94%E8%AE%B0/"><img class="next-cover" src="https://store-images.s-microsoft.com/image/apps.26922.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.793aac39-a892-4f68-88ca-95533c261ebd?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">《动手学深度学习》笔记</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/11/16/DL-RNN时序数据的采样/" title="RNN——时序数据的采样"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-16</div><div class="title">RNN——时序数据的采样</div></div></a></div><div><a href="/2020/10/28/DL-CNN卷积神经网络/" title="Convolutional Neural Network卷积神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.59240.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.7fc14922-0e06-4b88-9456-ac21927ad857?w=672&h=378&q=80&mode=letterbox&background=%23FFE4E4E4&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-28</div><div class="title">Convolutional Neural Network卷积神经网络</div></div></a></div><div><a href="/2020/10/28/DL-《动手学深度学习》笔记/" title="《动手学深度学习》笔记"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.26922.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.793aac39-a892-4f68-88ca-95533c261ebd?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-28</div><div class="title">《动手学深度学习》笔记</div></div></a></div><div><a href="/2020/10/30/DL-线性回归模型/" title="Linear Regression线性回归模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.8755.14309757982396439.717bf586-020c-4e5f-9970-26635abeab18.0e591ced-1c02-46b7-a929-0b4f3e984b8a?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-30</div><div class="title">Linear Regression线性回归模型</div></div></a></div><div><a href="/2020/10/31/DL-softmax回归模型/" title="softmax回归模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.53636.14077318991609137.74bb1f9d-01ce-4ec6-aecf-81719875e023.05ba4878-0779-4c67-b36d-5fba9acee597?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-31</div><div class="title">softmax回归模型</div></div></a></div><div><a href="/2020/11/09/DL-CNN经典论文——LeNet模型复现/" title="CNN经典算法——LeNet模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-09</div><div class="title">CNN经典算法——LeNet模型</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 By 侯三多</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: '6kxIlys6O892N2aKzQ1855Ad-MdYXbMMI',
      appKey: 'TYEDtfslCH4QT0ODMlHGHaGc',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><script src="//code.tidio.co/jtw2gf0ig0ylkc0so38yv6a0syags4zs.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script></div></body></html>