<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文-深度学习综述 | 三多之路</title><meta name="keywords" content="Deep Learning,Paper Recurrence"><meta name="author" content="侯三多"><meta name="copyright" content="侯三多"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (Three Giants’ Survey)   深度学习允许由多个处理层组成的计算模型学习具有多个抽象层次的数据表示。这些方法极大地提高了语音识别、视觉对象识别、对象检测和许多其他领域(">
<meta property="og:type" content="article">
<meta property="og:title" content="论文-深度学习综述">
<meta property="og:url" content="http://example.com/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/index.html">
<meta property="og:site_name" content="三多之路">
<meta property="og:description" content="LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (Three Giants’ Survey)   深度学习允许由多个处理层组成的计算模型学习具有多个抽象层次的数据表示。这些方法极大地提高了语音识别、视觉对象识别、对象检测和许多其他领域(">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2020-11-18T06:12:33.000Z">
<meta property="article:modified_time" content="2021-01-14T05:41:18.385Z">
<meta property="article:author" content="侯三多">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Paper Recurrence">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: 侯三多","link":"Link: ","source":"Source: 三多之路","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-01-14 13:41:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">20</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#The-difference-between-Machie-learning-and-Deep-Learning"><span class="toc-number">1.</span> <span class="toc-text">The difference between Machie learning and Deep Learning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Supervised-Learning"><span class="toc-number">2.</span> <span class="toc-text">Supervised Learning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Backpropagation-to-train-multilayer-architectures"><span class="toc-number">3.</span> <span class="toc-text">Backpropagation to train multilayer architectures</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Convolutional-Neural-Network"><span class="toc-number">4.</span> <span class="toc-text">Convolutional Neural Network</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Image-understanding-with-deep-convolutional-networks"><span class="toc-number">5.</span> <span class="toc-text">Image understanding with deep convolutional networks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Distributed-representations-and-language-processing"><span class="toc-number">6.</span> <span class="toc-text">Distributed representations and language processing</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Recurrent-Neural-Network"><span class="toc-number">7.</span> <span class="toc-text">Recurrent Neural Network</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">三多之路</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">论文-深度学习综述</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-11-18T06:12:33.000Z" title="Created 2020-11-18 14:12:33">2020-11-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-01-14T05:41:18.385Z" title="Updated 2021-01-14 13:41:18">2021-01-14</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>9min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><blockquote>
<p>LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “<strong>Deep learning</strong>.” Nature 521.7553 (2015): 436-444. [<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">pdf]</a> <strong>(Three Giants’ Survey)</strong> </p>
</blockquote>
<p>深度学习允许由多个处理层组成的计算模型学习具有多个抽象层次的数据表示。这些方法极大地提高了语音识别、视觉对象识别、对象检测和许多其他领域(如药物发现和基因组学)的技术水平。深度学习通过使用反向传播算法指示机器应该如何改变其内部参数来发现大型数据集中复杂的结构，该内部参数用于从前一层的表示计算每一层的表示。深度<strong>卷积网络</strong>在处理图像、视频、语音和音频方面带来了突破，而<strong>循环网络</strong>则照亮了文本和语音等连续数据。</p>
<h1 id="The-difference-between-Machie-learning-and-Deep-Learning"><a href="#The-difference-between-Machie-learning-and-Deep-Learning" class="headerlink" title="The difference between Machie learning and Deep Learning"></a>The difference between Machie learning and Deep Learning</h1><p>传统的机器学习技术在处理原始形式的自然数据方面能力有限。几十年来，构建模式识别或机器学习系统需要仔细的工程设计和大量的领域专业知识来设计特征提取器；</p>
<p>表示学习是一套方法，它允许机器获得原始数据，并自动发现检测或分类所需的表示。深度学习方法是具有多层次表示的表示学习方法，通过组合简单但非线性的模块获得，每个模块将一个层次的表示(从原始输入开始)转换为更高、稍微抽象的层次的表示。对于分类任务，更高层次的表征放大了对辨别和抑制无关变化很重要的输入方面。对于分类任务，更高层次的表征放大了对辨别和抑制无关变化很重要的输入方面。<strong>深度学习的关键方面是这些特征层不是由人类工程师设计的:它们是使用通用学习程序从数据中学习的。</strong></p>
<p>深度学习在不久的将来会有更多的成功，因为它只需要很少的手工工程，所以它可以很容易地利用可用计算和数据量的增加。目前正在为深度神经网络开发的新学习算法和架构只会加速这一进展。</p>
<h1 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h1><p>机器学习最常见的形式，不管深入与否，都是监督学习。以图像分类为例，首先需要收集大量数据，在训练过程中，机器会显示一个图像，并以分数向量的形式产生输出，每个类别一个分数。我们希望期望的类别在所有类别中得分最高，但这不太可能在训练前发生。我们计算一个<strong>目标函数，</strong>该函数测量输出分数和期望分数模式之间的误差(或距离)。然后，机器修改其内部可调参数，以减少这一误差。这些可调参数通常被称为<strong>权重</strong>，是实数，可以被视为定义机器输入输出功能的“旋钮”。在一个典型的深度学习系统中，可能有上亿个这样的可调权重，以及上亿个用来训练机器的标记例子。为了适当地调整权重向量，学习算法<strong>计算梯度向量</strong>，对于每个权重，梯度向量指示如果权重增加很小的量，误差将增加或减少多少。权重向量随后被调整到与梯度向量相反的方向。</p>
<p>在实践中，大多数从业者使用一种叫做随机梯度下降(SGD)的方法。这包括显示几个示例的输入向量，计算输出和误差，计算这些示例的平均梯度，并相应地调整权重。对训练集中的许多小样本集重复该过程，直到目标函数的平均值停止下降。之所以称之为随机，是因为每一个小例子都给出了所有例子的平均梯度的噪声估计。<strong>与复杂得多的优化技术相比，这个简单的过程通常能惊人地快速找到一组好的权重</strong>。经过培训后，系统的性能在一组不同的例子上进行测量，称为测试集。这用来测试机器的泛化能力——它对训练中从未见过的新输入产生合理答案的能力。当前机器学习的许多实际应用在手工设计的特征上使用线性分类器。两类线性分类器计算特征向量分量的加权和。如果加权和高于阈值，则输入被分类为属于特定类别。</p>
<p>浅层分类器需要一个好的特征提取器来解决选择性不变性的困境——<strong>一个产生对图像中对辨别很重要的方面有选择性的表示，但对不相关的方面如动物的姿势不变的表示</strong>。为了使分类器更强大，可以使用通用的非线性特征，如核方法，但是通用的特征，如高斯核产生的特征，不允许学习者远离训练示例进行概括。<strong>传统的选择是</strong>手工设计好的特征提取器，这需要大量的工程技术和领域专业知识。但是如果使用通用的学习程序可以自动学习好的特性，这一切都可以避免。<strong>这是深度学习的关键优势。</strong></p>
<p><strong>深度学习架构是简单模块的多层堆栈，所有(或大部分)模块都需要学习，其中许多模块计算非线性输入输出映射。堆栈中的每个模块转换其输入，以增加表示的选择性和不变性。有了多个非线性层，比如深度为5到20，系统可以实现极其复杂的输入功能，同时对微小的细节敏感(区分萨摩耶和白狼)，对背景、姿势、照明和周围对象等不相关的大变化不敏感。</strong></p>
<h1 id="Backpropagation-to-train-multilayer-architectures"><a href="#Backpropagation-to-train-multilayer-architectures" class="headerlink" title="Backpropagation to train multilayer architectures"></a>Backpropagation to train multilayer architectures</h1><p>多层架构可以通过简单的随机梯度下降来训练。只要模块是其输入和内部权重的相对平滑的函数，就可以使用反向传播过程来计算梯度。计算目标函数相对于多层堆叠模块的<strong>权重的梯度的反向传播过程</strong>只不过是导数链式法则的实际应用。关键的见解是，目标相对于模块输入的导数(或梯度)可以通过从相对于该模块输出(或后续模块输入)的梯度向后工作来计算。反向传播方程可以重复应用，以通过所有模块传播梯度，从顶部的输出(网络产生其预测)一直到底部(外部输入被馈送)。一旦计算出这些梯度，就可以直接计算每个模块权重的梯度。</p>
<p>目前最流行的非线性函数是**整流线性单元(ReLU)**，简单来说就是半波整流器f(z) =  max(z，0)。在过去的几十年里，神经网络使用更平滑的非线性，例如tanh(z)或1/(1+exp(z))，但是ReLU通常在具有许多层的网络中学习得更快，允许在没有无监督预训练的情况下训练深度监督网络28。</p>
<p>人们普遍认为，学习有用的、多阶段的、几乎没有先验知识的特征提取器是不可行的。特别是，人们普遍认为简单的梯度下降会陷入较差的<strong>局部极小值——权重配置</strong>，对于这种配置，任何微小的变化都不会降低平均误差。在实践中，差的局部极小值很少是大网络的问题。不管初始条件如何，系统几乎总是能得到质量非常相似的解。最近的理论和经验结果强烈表明，局部最小值一般来说不是一个严重的问题。取而代之的是，地形被大量的鞍点组合在一起，其中坡度为零，表面在大多数维度上向上弯曲，而在大多数维度上向下弯曲</p>
<h1 id="Convolutional-Neural-Network"><a href="#Convolutional-Neural-Network" class="headerlink" title="Convolutional Neural Network"></a>Convolutional Neural Network</h1><p>卷积神经网络被设计为处理以多阵列形式出现的数据，例如由三个2D阵列组成的彩色图像，包含三个颜色通道中的像素强度。许多数据形式是多阵列的形式:信号和序列的1D，包括语言；2D用于图像或音频频谱图；和3D用于视频或体积图像。利用自然信号特性的ConvNets背后有四个关键思想:<strong>本地连接、共享权重、池化和使用多个层。</strong></p>
<p>前几个阶段由两种类型的层组成:卷积层和汇集层。卷积层中的单元被组织在特征图中，其中每个单元通过一组称为滤波器组的权重与前一层的特征图中的局部片相连。这个局部加权和的结果然后通过一个非线性，如ReLU。要素地图中的所有单元共享同一个滤波器组。一个图层中的不同要素地图使用不同的滤波器组。这种架构有两个原因。首先，在图像等阵列数据中，局部值组通常高度相关，形成易于检测的独特局部图案。第二，图像和其他信号的局部统计对于位置是不变的。换句话说，如果一个图案可以出现在图像的一部分，它可以出现在任何地方，因此不同位置的单元共享相同的权重，并在阵列的不同部分检测相同的图案。</p>
<p>一个典型的池单元计算一个要素地图(或几个要素地图)中单元的局部斑块的最大值。相邻的汇集单元从移位超过一行或一列的块中获取输入，从而降低表示的维数，并创建对小移位和失真的不变性。卷积、非线性和汇集的两个或三个阶段被堆叠，随后是更多的卷积和全连接层。</p>
<p>深度神经网络利用了许多自然信号是组成层次的特性，其中较高级别的特征是通过组成较低级别的特征获得的。在图像中，边缘的局部组合形成图案，图案组合成零件，零件形成物体。从声音到音素、音素、音节、单词和句子，语音和文本中存在类似的层次结构。当前一层中的元素在位置和外观上发生变化时，池化允许表示变化很小。</p>
<h1 id="Image-understanding-with-deep-convolutional-networks"><a href="#Image-understanding-with-deep-convolutional-networks" class="headerlink" title="Image understanding with deep convolutional networks"></a>Image understanding with deep convolutional networks</h1><p>在2012年ImageNet竞赛之前，ConvNets在很大程度上被主流计算机视觉和机器学习社区所抛弃。当深度卷积网络应用于包含1000个不同类别的约100万幅网络图像的数据集时，它们取得了惊人的结果，几乎将最佳竞争方法的错误率减半。<strong>这一成功来自于GPU、ReLUs(一种称为dropout的新正则化技术)和通过变形现有样本来生成更多训练样本的技术的有效使用。这</strong>一成功带来了计算机视觉的革命；ConvNets现在是几乎所有识别和检测任务的主要方法，并接近人类在某些任务上的表现。</p>
<h1 id="Distributed-representations-and-language-processing"><a href="#Distributed-representations-and-language-processing" class="headerlink" title="Distributed representations and language processing"></a>Distributed representations and language processing</h1><p>这一部分回看论文即可</p>
<h1 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h1><p>RNNs一旦及时展开(图5)，可以被视为非常深的前馈网络，其中所有层共享相同的权重。虽然他们的主要目的是学习长期依赖性，但理论和经验证据表明，很难学会将信息存储很长时间78。为了纠正这一点，一个想法是用一个明确的内存来扩充网络。这种类型的第一个提议是使用特殊隐藏单元的长短期记忆(LSTM)网络，其自然行为是长时间记住输入79。一种叫做存储单元的特殊单元就像累加器或门控泄漏神经元一样:它在下一个权重为1的时间步与自己相连，因此它复制自己的实值状态并累积外部信号，但这种自连接被另一个单元多重门控，该单元学习决定何时清除存储器内容。LSTM网络随后被证明比传统的神经网络更有效，尤其是当它们在每个时间步长有几层时，使得整个语音识别系统能够从声学一直到转录中的字符序列</p>
<img src="/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/1.jpg" class></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/12/17/Cesium%E4%B8%AD%E7%9A%84Entities/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Cesium之Entities1</div></div></a></div><div class="next-post pull-right"><a href="/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/"><img class="next-cover" src="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">RNN——时序数据的采样</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/11/09/DL-CNN经典论文——LeNet模型复现/" title="CNN经典算法——LeNet模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-09</div><div class="title">CNN经典算法——LeNet模型</div></div></a></div><div><a href="/2020/11/10/DL-CNN经典论文——VGG模型/" title="CNN经典算法——VGG模型"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-10</div><div class="title">CNN经典算法——VGG模型</div></div></a></div><div><a href="/2020/11/10/DL-CNN经典论文——AlexNet模型/" title="CNN经典算法——AlexNet模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-10</div><div class="title">CNN经典算法——AlexNet模型</div></div></a></div><div><a href="/2020/11/12/DL-CNN经典论文—-NiN模型/" title="CNN经典论文—-NiN模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&q=90&h=1080&w=1920A"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-12</div><div class="title">CNN经典论文—-NiN模型</div></div></a></div><div><a href="/2020/10/28/DL-CNN卷积神经网络/" title="Convolutional Neural Network卷积神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.59240.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.7fc14922-0e06-4b88-9456-ac21927ad857?w=672&h=378&q=80&mode=letterbox&background=%23FFE4E4E4&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-28</div><div class="title">Convolutional Neural Network卷积神经网络</div></div></a></div><div><a href="/2020/10/29/DL-RNN循环神经网络/" title="Recurrent Neural Network循环神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&h=609&q=90&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-29</div><div class="title">Recurrent Neural Network循环神经网络</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 侯三多</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: '6kxIlys6O892N2aKzQ1855Ad-MdYXbMMI',
      appKey: 'TYEDtfslCH4QT0ODMlHGHaGc',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><script src="//code.tidio.co/jtw2gf0ig0ylkc0so38yv6a0syags4zs.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script></div></body></html>