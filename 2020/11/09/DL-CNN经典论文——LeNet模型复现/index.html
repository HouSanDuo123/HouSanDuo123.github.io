<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CNN经典算法——LeNet模型 | 三多之路</title><meta name="keywords" content="Deep Learning,Paper Recurrence,CNN"><meta name="author" content="侯三多"><meta name="copyright" content="侯三多"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="LeNet模型介绍  LeNet网络基本架构为：conv1 (6) -&gt; pool1 -&gt; conv2 (16) -&gt; pool2 -&gt; fc3 (120) -&gt; fc4 (84) -&gt; fc5 (10) -&gt; softmax，括号内数字表示channel数。 该网络包含五层，两个卷积（卷积层、池化层)，两个全连接层，一个输出层。 其中卷积层的卷积核大小为">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN经典算法——LeNet模型">
<meta property="og:url" content="http://example.com/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/index.html">
<meta property="og:site_name" content="三多之路">
<meta property="og:description" content="LeNet模型介绍  LeNet网络基本架构为：conv1 (6) -&gt; pool1 -&gt; conv2 (16) -&gt; pool2 -&gt; fc3 (120) -&gt; fc4 (84) -&gt; fc5 (10) -&gt; softmax，括号内数字表示channel数。 该网络包含五层，两个卷积（卷积层、池化层)，两个全连接层，一个输出层。 其中卷积层的卷积核大小为">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&q=90&h=1080&w=1920">
<meta property="article:published_time" content="2020-11-09T02:59:46.000Z">
<meta property="article:modified_time" content="2020-11-16T01:23:21.712Z">
<meta property="article:author" content="侯三多">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Paper Recurrence">
<meta property="article:tag" content="CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&q=90&h=1080&w=1920"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: 侯三多","link":"Link: ","source":"Source: 三多之路","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-11-16 09:23:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">20</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#LeNet%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">LeNet模型介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0"><span class="toc-number">2.</span> <span class="toc-text">LeNet模型复现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8ESequntial%E7%B1%BB%E6%9E%84%E9%80%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">基于Sequntial类构造模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E7%9C%8B%E7%9C%8B%E5%90%84%E5%B1%82%E7%9A%84%E8%BE%93%E5%87%BA%E5%BD%A2%E7%8A%B6"><span class="toc-number">2.2.</span> <span class="toc-text">输入一个测试数据看看各层的输出形状</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%83%E7%94%A8GPU%E8%AE%A1%E7%AE%97"><span class="toc-number">2.3.</span> <span class="toc-text">调用GPU计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.4.</span> <span class="toc-text">加载数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E5%87%86%E7%A1%AE%E5%BA%A6"><span class="toc-number">2.5.</span> <span class="toc-text">评估准确度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">2.6.</span> <span class="toc-text">训练</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&amp;q=90&amp;h=1080&amp;w=1920)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">三多之路</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">CNN经典算法——LeNet模型</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-11-09T02:59:46.000Z" title="Created 2020-11-09 10:59:46">2020-11-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-11-16T01:23:21.712Z" title="Updated 2020-11-16 09:23:21">2020-11-16</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">1.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>7min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="LeNet模型介绍"><a href="#LeNet模型介绍" class="headerlink" title="LeNet模型介绍"></a>LeNet模型介绍</h1><img src="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/1.jpg" class>

<p>LeNet网络基本架构为：conv1 (6) -&gt; pool1 -&gt; conv2 (16) -&gt; pool2 -&gt; fc3 (120) -&gt; fc4 (84) -&gt; fc5 (10) -&gt; softmax，括号内数字表示channel数。</p>
<p>该网络包含五层，两个卷积（卷积层、池化层)，两个全连接层，一个输出层。</p>
<p>其中卷积层的卷积核大小为5x5，stride=1；池化层为最大池化层，卷积核大小为2x2，strides=2；全连接层的输出个数分别为120， 84， 10.</p>
<h1 id="LeNet模型复现"><a href="#LeNet模型复现" class="headerlink" title="LeNet模型复现"></a>LeNet模型复现</h1><p>参考：《动手学深度学习》Chapter5</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> d2lzh <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> loss <span class="keyword">as</span> gloss, nn</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>

<h2 id="基于Sequntial类构造模型"><a href="#基于Sequntial类构造模型" class="headerlink" title="基于Sequntial类构造模型"></a>基于Sequntial类构造模型</h2><p>经历一次卷积层，其高和宽为(h-k+1)*(w-k+1)；经历一次池化层，其宽和高减半；这个过程重复两次</p>
<p>第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。</p>
<p>全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nn.Conv2D(channels=<span class="number">6</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line">        nn.Conv2D(channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line">        </span><br><span class="line">        nn.Dense(<span class="number">120</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">        nn.Dense(<span class="number">84</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">        nn.Dense(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h2 id="输入一个测试数据看看各层的输出形状"><a href="#输入一个测试数据看看各层的输出形状" class="headerlink" title="输入一个测试数据看看各层的输出形状"></a>输入一个测试数据看看各层的输出形状</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = nd.random.uniform(shape=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">net.initialize()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    print(layer.name, <span class="string">&#x27;output shape:\t&#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure>

<pre><code>conv0 output shape:     (1, 6, 28, 28)
pool0 output shape:     (1, 6, 14, 14)
conv1 output shape:     (1, 16, 10, 10)
pool1 output shape:     (1, 16, 5, 5)
dense0 output shape:     (1, 120)
dense1 output shape:     (1, 84)
dense2 output shape:     (1, 10)</code></pre>
<h2 id="调用GPU计算"><a href="#调用GPU计算" class="headerlink" title="调用GPU计算"></a>调用GPU计算</h2><p>这里在安装的时候，不能直接用”pip install mxnet”,要用”pip install mxnet-cu100”cu100需要根据自己的cuda版本来更改<br>只有安装gpu版本的mxnet，才可使用gpu</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span>():</span> </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu()</span><br><span class="line">        _ = nd.zeros((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line">ctx = try_gpu()</span><br><span class="line">ctx</span><br></pre></td></tr></table></figure>


<pre><code>gpu(0)</code></pre>
<h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><p>采用小批次训练，每个批次设置为256个</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)</span><br></pre></td></tr></table></figure>

<h2 id="评估准确度"><a href="#评估准确度" class="headerlink" title="评估准确度"></a>评估准确度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">data_iter, net, ctx</span>):</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="comment">#将X，y复制到GPU中</span></span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        acc_sum += (net(X).argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br></pre></td></tr></table></figure>

<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span>(<span class="params">net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training on&#x27;</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            y = y.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net, ctx)</span><br><span class="line">        print(<span class="string">&#x27;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, &#x27;</span></span><br><span class="line">              <span class="string">&#x27;time %.1f sec&#x27;</span></span><br><span class="line">              %(epoch+<span class="number">1</span>, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs = <span class="number">0.95</span>, <span class="number">35</span></span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">&#x27;sgd&#x27;</span>, &#123;<span class="string">&#x27;learning_rate&#x27;</span>: lr&#125;)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></table></figure>

<pre><code>training on gpu(0)
epoch 1, loss 2.3222, train acc 0.102, test acc 0.100, time 2.2 sec
epoch 2, loss 1.5564, train acc 0.396, test acc 0.650, time 2.2 sec
epoch 3, loss 0.8515, train acc 0.667, test acc 0.716, time 2.2 sec
epoch 4, loss 0.6984, train acc 0.722, test acc 0.749, time 2.2 sec
epoch 5, loss 0.6321, train acc 0.750, test acc 0.769, time 2.1 sec
epoch 6, loss 0.5789, train acc 0.771, test acc 0.793, time 2.2 sec
epoch 7, loss 0.5328, train acc 0.790, test acc 0.801, time 2.2 sec
epoch 8, loss 0.4997, train acc 0.805, test acc 0.820, time 2.2 sec
epoch 9, loss 0.4771, train acc 0.815, test acc 0.831, time 2.2 sec
epoch 10, loss 0.4515, train acc 0.829, test acc 0.840, time 2.2 sec
epoch 11, loss 0.4339, train acc 0.837, test acc 0.841, time 2.1 sec
epoch 12, loss 0.4220, train acc 0.841, test acc 0.852, time 2.2 sec
epoch 13, loss 0.4057, train acc 0.849, test acc 0.859, time 2.2 sec
epoch 14, loss 0.3916, train acc 0.854, test acc 0.856, time 2.2 sec
epoch 15, loss 0.3778, train acc 0.860, test acc 0.868, time 2.2 sec
epoch 16, loss 0.3675, train acc 0.865, test acc 0.873, time 2.3 sec
epoch 17, loss 0.3558, train acc 0.868, test acc 0.870, time 2.2 sec
epoch 18, loss 0.3472, train acc 0.873, test acc 0.868, time 2.2 sec
epoch 19, loss 0.3395, train acc 0.875, test acc 0.879, time 2.2 sec
epoch 20, loss 0.3335, train acc 0.878, test acc 0.873, time 2.2 sec
epoch 21, loss 0.3252, train acc 0.881, test acc 0.873, time 2.2 sec
epoch 22, loss 0.3194, train acc 0.882, test acc 0.883, time 2.2 sec
epoch 23, loss 0.3151, train acc 0.884, test acc 0.879, time 2.2 sec
epoch 24, loss 0.3124, train acc 0.884, test acc 0.882, time 2.2 sec
epoch 25, loss 0.3072, train acc 0.886, test acc 0.883, time 2.2 sec
epoch 26, loss 0.3032, train acc 0.888, test acc 0.885, time 2.2 sec
epoch 27, loss 0.2977, train acc 0.890, test acc 0.885, time 2.3 sec
epoch 28, loss 0.2956, train acc 0.891, test acc 0.880, time 2.2 sec
epoch 29, loss 0.2903, train acc 0.893, test acc 0.887, time 2.2 sec
epoch 30, loss 0.2902, train acc 0.893, test acc 0.890, time 2.1 sec
epoch 31, loss 0.2842, train acc 0.895, test acc 0.889, time 2.2 sec
epoch 32, loss 0.2807, train acc 0.897, test acc 0.890, time 2.2 sec
epoch 33, loss 0.2800, train acc 0.896, test acc 0.891, time 2.3 sec
epoch 34, loss 0.2745, train acc 0.899, test acc 0.892, time 2.2 sec
epoch 35, loss 0.2731, train acc 0.899, test acc 0.892, time 2.2 sec</code></pre>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/dan_teng/article/details/87192430">https://blog.csdn.net/dan_teng/article/details/87192430</a></p>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a><a class="post-meta__tags" href="/tags/CNN/">CNN</a></div><div class="post_share"><div class="social-share" data-image="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/"><img class="prev-cover" src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">CNN经典算法——AlexNet模型</div></div></a></div><div class="next-post pull-right"><a href="/2020/11/04/ML-my-hw3-cnn/"><img class="next-cover" src="https://store-images.s-microsoft.com/image/apps.11416.13666079135464041.262c63a4-3d2e-4fcb-862d-2038cfd9fdf3.50843114-bc48-4a75-9018-4a09fa8ccc4d?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">《机器学习（李宏毅2020spring）》作业3：CNN</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/11/10/DL-CNN经典论文——VGG模型/" title="CNN经典算法——VGG模型"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-10</div><div class="title">CNN经典算法——VGG模型</div></div></a></div><div><a href="/2020/11/10/DL-CNN经典论文——AlexNet模型/" title="CNN经典算法——AlexNet模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-10</div><div class="title">CNN经典算法——AlexNet模型</div></div></a></div><div><a href="/2020/11/12/DL-CNN经典论文—-NiN模型/" title="CNN经典论文—-NiN模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&q=90&h=1080&w=1920A"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-12</div><div class="title">CNN经典论文—-NiN模型</div></div></a></div><div><a href="/2020/10/28/DL-CNN卷积神经网络/" title="Convolutional Neural Network卷积神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.59240.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.7fc14922-0e06-4b88-9456-ac21927ad857?w=672&h=378&q=80&mode=letterbox&background=%23FFE4E4E4&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-28</div><div class="title">Convolutional Neural Network卷积神经网络</div></div></a></div><div><a href="/2020/11/18/论文-DeepLearning综述/" title="论文-深度学习综述"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-18</div><div class="title">论文-深度学习综述</div></div></a></div><div><a href="/2020/10/29/DL-RNN循环神经网络/" title="Recurrent Neural Network循环神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&h=609&q=90&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-29</div><div class="title">Recurrent Neural Network循环神经网络</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 By 侯三多</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: '6kxIlys6O892N2aKzQ1855Ad-MdYXbMMI',
      appKey: 'TYEDtfslCH4QT0ODMlHGHaGc',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><script src="//code.tidio.co/jtw2gf0ig0ylkc0so38yv6a0syags4zs.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script></div></body></html>