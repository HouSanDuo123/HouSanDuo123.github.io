<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>RNN——时序数据的采样 | 三多之路</title><meta name="keywords" content="Deep Learning,RNN"><meta name="author" content="侯三多"><meta name="copyright" content="侯三多"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="语言模型数据集读取数据集12345678from mxnet import ndimport randomimport zipfilewith zipfile.ZipFile(&amp;#x27;..&#x2F;data&#x2F;jaychou_lyrics.txt.zip&amp;#x27;) as zin:    with zin.open(&amp;#x27;jaychou_lyrics.txt&amp;#x27;) as f:">
<meta property="og:type" content="article">
<meta property="og:title" content="RNN——时序数据的采样">
<meta property="og:url" content="http://example.com/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/index.html">
<meta property="og:site_name" content="三多之路">
<meta property="og:description" content="语言模型数据集读取数据集12345678from mxnet import ndimport randomimport zipfilewith zipfile.ZipFile(&amp;#x27;..&#x2F;data&#x2F;jaychou_lyrics.txt.zip&amp;#x27;) as zin:    with zin.open(&amp;#x27;jaychou_lyrics.txt&amp;#x27;) as f:">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&q=90&h=1080&w=1920">
<meta property="article:published_time" content="2020-11-16T02:38:31.000Z">
<meta property="article:modified_time" content="2020-11-16T02:53:29.135Z">
<meta property="article:author" content="侯三多">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="RNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&q=90&h=1080&w=1920"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: 侯三多","link":"Link: ","source":"Source: 三多之路","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-11-16 10:53:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">21</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">语言模型数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.</span> <span class="toc-text">读取数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7"><span class="toc-number">1.2.</span> <span class="toc-text">时序数据的采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7"><span class="toc-number">1.3.</span> <span class="toc-text">随机采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E9%82%BB%E9%87%87%E6%A0%B7"><span class="toc-number">1.4.</span> <span class="toc-text">相邻采样</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&amp;q=90&amp;h=1080&amp;w=1920)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">三多之路</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">RNN——时序数据的采样</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-11-16T02:38:31.000Z" title="Created 2020-11-16 10:38:31">2020-11-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-11-16T02:53:29.135Z" title="Updated 2020-11-16 10:53:29">2020-11-16</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">1.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>6min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="语言模型数据集"><a href="#语言模型数据集" class="headerlink" title="语言模型数据集"></a>语言模型数据集</h1><h2 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(<span class="string">&#x27;../data/jaychou_lyrics.txt.zip&#x27;</span>) <span class="keyword">as</span> zin:</span><br><span class="line">    <span class="keyword">with</span> zin.open(<span class="string">&#x27;jaychou_lyrics.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        corpus_chars = f.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">corpus_chars[:<span class="number">40</span>]</span><br></pre></td></tr></table></figure>




<pre><code>&#39;想要有直升机\n想要和你飞到宇宙去\n想要和你融化在一起\n融化在宇宙里\n我每天每天每&#39;</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">corpus_chars = corpus_chars.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27; &#x27;</span>).replace(<span class="string">&#x27;\t&#x27;</span>, <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">corpus_chars = corpus_chars[<span class="number">0</span>:<span class="number">10000</span>]</span><br><span class="line">corpus_chars[<span class="number">0</span>:<span class="number">49</span>]</span><br></pre></td></tr></table></figure>




<pre><code>&#39;想要有直升机 想要和你飞到宇宙去 想要和你融化在一起 融化在宇宙里 我每天每天每天在想想想想著你 &#39;</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">idx_to_char = list(set(corpus_chars)) <span class="comment">#去重复，求得不重复的字符</span></span><br><span class="line">char_to_idx = dict([(char, i)<span class="keyword">for</span> i, char <span class="keyword">in</span> enumerate(idx_to_char)])<span class="comment"># 将字符与索引一一映射构造字典</span></span><br><span class="line">vocab_size = len(char_to_idx)</span><br><span class="line">print(vocab_size)</span><br><span class="line">print(char_to_idx[<span class="string">&#x27;有&#x27;</span>])</span><br><span class="line"><span class="comment">#print(idx_to_char)</span></span><br></pre></td></tr></table></figure>

<pre><code>1027
596</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">corpus_indices = [char_to_idx[char] <span class="keyword">for</span> char <span class="keyword">in</span> corpus_chars]</span><br><span class="line">sample = corpus_indices[:<span class="number">20</span>]</span><br><span class="line">print(<span class="string">&#x27;chars:&#x27;</span>, <span class="string">&#x27;&#x27;</span>.join([idx_to_char[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> sample]))</span><br><span class="line">print(<span class="string">&#x27;indices:&#x27;</span>, sample)</span><br></pre></td></tr></table></figure>

<pre><code>chars: 想要有直升机 想要和你飞到宇宙去 想要和
indices: [63, 155, 596, 58, 143, 855, 670, 63, 155, 607, 151, 597, 227, 181, 161, 459, 670, 63, 155, 607]</code></pre>
<h2 id="时序数据的采样"><a href="#时序数据的采样" class="headerlink" title="时序数据的采样"></a>时序数据的采样</h2><p>在训练过程中，我们每次需要随机读取小批量的样本x和标签值y，时序数据的一个样本通常包含多个连续的字符。以上文数据“<strong>想要有直升机 想要和你飞到宇宙去 想要和</strong>”为例，假设时间步数为5，样本序列中就会有五个字符——“<strong>想要有直升</strong>”，而标签序列的字符为样本字符在训练集中的下一个字符——“<strong>要有直升机</strong>”。</p>
<p>对于时序数据采样，我们有两种方法，随机采样和相邻采样</p>
<h2 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h2><p>batch_size为每个小批量的样本数，num_steps为单个样本的时间步数，随机采样中，每个样本为原始序列中任意截取长度为num_steps的一段序列，相邻的两个小批量在原始序列的位置并不一定相邻。因此，我们无法用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态。在训练模型时，每次随机采样前都需要重新初始化隐藏状态。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#随机采样</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter_random</span>(<span class="params">corpus_indices, batch_size, num_steps, ctx=None</span>):</span></span><br><span class="line">    <span class="comment"># 减1是因为输出的索引是相应输入的索引加1</span></span><br><span class="line">    num_examples = (len(corpus_indices) - <span class="number">1</span>) // num_steps <span class="comment">#下取整，得到的是总样本个数</span></span><br><span class="line">    epoch_size = num_examples // batch_size <span class="comment">#总共有多少个小批量样本，每个小批量样本个数为batch_size</span></span><br><span class="line"></span><br><span class="line">    example_indices = list(range(num_examples))<span class="comment">#打乱顺序</span></span><br><span class="line">    random.shuffle(example_indices)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回从pos开始的长为num_steps的序列</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_data</span>(<span class="params">pos</span>):</span></span><br><span class="line">        <span class="keyword">return</span> corpus_indices[pos: pos + num_steps]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch_size):</span><br><span class="line">        <span class="comment"># 每次读取batch_size个随机样本</span></span><br><span class="line">        i = i * batch_size</span><br><span class="line">        batch_indices = example_indices[i: i + batch_size]</span><br><span class="line">        X = [_data(j * num_steps) <span class="keyword">for</span> j <span class="keyword">in</span> batch_indices]</span><br><span class="line">        Y = [_data(j * num_steps + <span class="number">1</span>) <span class="keyword">for</span> j <span class="keyword">in</span> batch_indices]</span><br><span class="line">        <span class="keyword">yield</span> nd.array(X, ctx), nd.array(Y, ctx)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_seq = list(range(<span class="number">40</span>))</span><br><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter_random(my_seq, batch_size=<span class="number">2</span>, num_steps=<span class="number">6</span>):</span><br><span class="line">    print(<span class="string">&#x27;X: &#x27;</span>, X, <span class="string">&#x27;\nY:&#x27;</span>, Y, <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>X:  
[[ 6.  7.  8.  9. 10. 11.]
 [18. 19. 20. 21. 22. 23.]]
&lt;NDArray 2x6 @cpu(0)&gt; 
Y: 
[[ 7.  8.  9. 10. 11. 12.]
 [19. 20. 21. 22. 23. 24.]]
&lt;NDArray 2x6 @cpu(0)&gt; 

X:  
[[24. 25. 26. 27. 28. 29.]
 [ 0.  1.  2.  3.  4.  5.]]
&lt;NDArray 2x6 @cpu(0)&gt; 
Y: 
[[25. 26. 27. 28. 29. 30.]
 [ 1.  2.  3.  4.  5.  6.]]
&lt;NDArray 2x6 @cpu(0)&gt; 

X:  
[[12. 13. 14. 15. 16. 17.]
 [30. 31. 32. 33. 34. 35.]]
&lt;NDArray 2x6 @cpu(0)&gt; 
Y: 
[[13. 14. 15. 16. 17. 18.]
 [31. 32. 33. 34. 35. 36.]]
&lt;NDArray 2x6 @cpu(0)&gt; 

以这个输入的示例为例，针对单个X，每个X包含batch_size=2个批量的样本，每个样本包含num_steps=6个字符，而Y的每个样本为X每个样本的后一个字符；
然后我们比较相邻的两个X，会发现第一个X的首字符为６，而第二个X的首字符为24，两者不相邻。
同理我们可以比较相邻采样，这样就会更加容易理解。</code></pre>
<h2 id="相邻采样"><a href="#相邻采样" class="headerlink" title="相邻采样"></a>相邻采样</h2><p>除对原始序列做随机采样之外，我们还可以令相邻的两个随机小批量在原始序列上的位置相毗邻。这时候，我们就可以用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态，从而使下一个小批量的输出也取决于当前小批量的输入，并如此循环下去。这对实现循环神经网络造成了两方面影响：一方面， 在训练模型时，我们只需在每一个迭代周期开始时初始化隐藏状态；另一方面，当多个相邻小批量通过传递隐藏状态串联起来时，模型参数的梯度计算将依赖所有串联起来的小批量序列。同一迭代周期中，随着迭代次数的增加，梯度的计算开销会越来越大。 为了使模型参数的梯度计算只依赖一次迭代读取的小批量序列，我们可以在每次读取小批量前将隐藏状态从计算图中分离出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter_consecutive</span>(<span class="params">corpus_indices, batch_size, num_steps, ctx=None</span>):</span></span><br><span class="line">    corpus_indices = nd.array(corpus_indices, ctx=ctx)</span><br><span class="line">    data_len = len(corpus_indices) <span class="comment">#字符长度</span></span><br><span class="line">    batch_len = data_len // batch_size<span class="comment">#可以有多少个小批量</span></span><br><span class="line">    indices = corpus_indices[<span class="number">0</span>: batch_size*batch_len].reshape((batch_size, batch_len))<span class="comment">#转换维度batch_size行，batch_len列</span></span><br><span class="line">    epoch_size = (batch_len - <span class="number">1</span>) // num_steps</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch_size):</span><br><span class="line">        i = i * num_steps</span><br><span class="line">        X = indices[:, i: i + num_steps]</span><br><span class="line">        Y = indices[:, i + <span class="number">1</span>: i + num_steps + <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">yield</span> X, Y</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter_consecutive(my_seq, batch_size=<span class="number">2</span>, num_steps=<span class="number">6</span>):</span><br><span class="line">    print(<span class="string">&#x27;X: &#x27;</span>, X, <span class="string">&#x27;\nY:&#x27;</span>, Y, <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>X:  
[[ 0.  1.  2.  3.  4.  5.]
 [20. 21. 22. 23. 24. 25.]]
&lt;NDArray 2x6 @cpu(0)&gt; 
Y: 
[[ 1.  2.  3.  4.  5.  6.]
 [21. 22. 23. 24. 25. 26.]]
&lt;NDArray 2x6 @cpu(0)&gt; 

X:  
[[ 6.  7.  8.  9. 10. 11.]
 [26. 27. 28. 29. 30. 31.]]
&lt;NDArray 2x6 @cpu(0)&gt; 
Y: 
[[ 7.  8.  9. 10. 11. 12.]
 [27. 28. 29. 30. 31. 32.]]
&lt;NDArray 2x6 @cpu(0)&gt; 

X:  
[[12. 13. 14. 15. 16. 17.]
 [32. 33. 34. 35. 36. 37.]]
&lt;NDArray 2x6 @cpu(0)&gt; 
Y: 
[[13. 14. 15. 16. 17. 18.]
 [33. 34. 35. 36. 37. 38.]]
&lt;NDArray 2x6 @cpu(0)&gt; </code></pre>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/RNN/">RNN</a></div><div class="post_share"><div class="social-share" data-image="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">论文-深度学习综述</div></div></a></div><div class="next-post pull-right"><a href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/"><img class="next-cover" src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&amp;q=90&amp;h=1080&amp;w=1920A" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">CNN经典论文—-NiN模型</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/10/29/DL-RNN循环神经网络/" title="Recurrent Neural Network循环神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&h=609&q=90&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-29</div><div class="title">Recurrent Neural Network循环神经网络</div></div></a></div><div><a href="/2020/10/28/DL-CNN卷积神经网络/" title="Convolutional Neural Network卷积神经网络"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.59240.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.7fc14922-0e06-4b88-9456-ac21927ad857?w=672&h=378&q=80&mode=letterbox&background=%23FFE4E4E4&format=jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-28</div><div class="title">Convolutional Neural Network卷积神经网络</div></div></a></div><div><a href="/2020/10/28/DL-《动手学深度学习》笔记/" title="《动手学深度学习》笔记"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.26922.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.793aac39-a892-4f68-88ca-95533c261ebd?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-28</div><div class="title">《动手学深度学习》笔记</div></div></a></div><div><a href="/2020/10/30/DL-线性回归模型/" title="Linear Regression线性回归模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.8755.14309757982396439.717bf586-020c-4e5f-9970-26635abeab18.0e591ced-1c02-46b7-a929-0b4f3e984b8a?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-30</div><div class="title">Linear Regression线性回归模型</div></div></a></div><div><a href="/2020/10/31/DL-softmax回归模型/" title="softmax回归模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.53636.14077318991609137.74bb1f9d-01ce-4ec6-aecf-81719875e023.05ba4878-0779-4c67-b36d-5fba9acee597?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-31</div><div class="title">softmax回归模型</div></div></a></div><div><a href="/2020/11/09/DL-CNN经典论文——LeNet模型复现/" title="CNN经典算法——LeNet模型"><img class="cover" src="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&q=90&h=1080&w=1920"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-09</div><div class="title">CNN经典算法——LeNet模型</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 侯三多</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: '6kxIlys6O892N2aKzQ1855Ad-MdYXbMMI',
      appKey: 'TYEDtfslCH4QT0ODMlHGHaGc',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><script src="//code.tidio.co/jtw2gf0ig0ylkc0so38yv6a0syags4zs.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script></div></body></html>