<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>三多之路 - From Zero To One Hundred</title><meta name="author" content="侯三多"><meta name="copyright" content="侯三多"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="追求极致之美">
<meta property="og:type" content="website">
<meta property="og:title" content="三多之路">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="三多之路">
<meta property="og:description" content="追求极致之美">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:author" content="侯三多">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: 侯三多","link":"Link: ","source":"Source: 三多之路","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2020-11-12 20:16:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">16</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(/img/background3.JPG)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">三多之路</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">三多之路</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/28/DL-%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%94%E8%AE%B0/" title="《动手学深度学习》笔记">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.26922.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.793aac39-a892-4f68-88ca-95533c261ebd?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《动手学深度学习》笔记"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/28/DL-%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%94%E8%AE%B0/" title="《动手学深度学习》笔记">《动手学深度学习》笔记</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack article-meta__icon sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-28T10:10:44.000Z" title="Created 2020-10-28 18:10:44">2020-10-28</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></span></div><div class="content">相关资料：书籍地址
maxnet官网
Chapter2：预备知识获取和运行本书的代码环境配置按照官网教程即可实现，可能会遇到一个问题，我的cuda是10.0版本，在修改environment文件时要写成mxnet100，这样就可以运行了。
另外我是在GPU服务器上运行，为了可以在自己的浏览器打开jupyternotebook，需要设置一下，具体设置自行百度，唯一需要注意的是，修改文件后一定要把修改配置前的“#”删去，否则是无效的。
Chapter3：深度学习基础线性回归当模型和损失函数形式较为简单时，其误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。
大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）
对于求解数值解，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用，其做法就是选定一个初始点w0，然后w0沿着梯度下降到方向移动一定的距离，知道找到最小点。
线性回归模 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/15/ML-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="《机器学习（李宏毅2020spring）》学习笔记(持续更新)">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.30419.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.4b0fd7af-3555-4a2d-adc6-a91cf51f30bb?w=672&amp;h=378&amp;q=80&amp;mode=letterbox&amp;background=%23FFE4E4E4&amp;format=jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《机器学习（李宏毅2020spring）》学习笔记(持续更新)"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/15/ML-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="《机器学习（李宏毅2020spring）》学习笔记(持续更新)">《机器学习（李宏毅2020spring）》学习笔记(持续更新)</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack article-meta__icon sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-15T11:18:35.000Z" title="Created 2020-10-15 19:18:35">2020-10-15</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></span></div><div class="content">相关资料李宏毅老师：个人主页在这里有上课的课件、课后题目数据集及源码
课程视频（B站）：B站
课程笔记：GitHub1、GitHub2
作业说明及范例：GitHub
动手学深度学习：这本书也不错，理论与实践结合紧密
Neural Networks and Deep Learning
CNN十大经典论文
TensorFlow：http://c.biancheng.net/view/1911.html
这个也可以参考一下：https://blog.csdn.net/iteapoy/article/details/105382315
Learning Map



HomeWork


序号
任务
完成情况
完成时间



1
Linear Regression
✔Regression
2020/10/19


2
Classification
✔Classification
2020/10/21


3
CNN
待完成



P4 Basic ConceptBias and Variance如何区分理解？
偏差(Bias)和方差(Variance)——机器学习中的模型选择
P5Gradie ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&amp;q=90&amp;h=1080&amp;w=1920A" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典论文—-NiN模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型">CNN经典论文—-NiN模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-12T08:40:31.000Z" title="Created 2020-11-12 16:40:31">2020-11-12</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a></span></div><div class="content">NiNe同AlexNet和VGG网络的区别

1x1卷积层卷积窗口形状为1×1（kh=kw=1）的多通道卷积层。我们通常称之为1×1卷积层，并将其中的卷积运算称为1×1卷积。因为使用了最小窗口，1×1卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能，其主要计算发生在通道维上。下图展示了使用输入通道数为3、输出通道数为2的1×1卷积核的互相关计算。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本那么1×1卷积层的作用与全连接层等价。


网络结构
传统的convolution层
传统的卷积层，通过卷积核得到




单通道mlpconv层


跨通道的mlpconv



</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——VGG模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型">CNN经典算法——VGG模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-10T12:02:31.000Z" title="Created 2020-11-10 20:02:31">2020-11-10</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a></span></div><div class="content">VGG原理

VGG有两种结构，分别是VGG16（上图D列）和VGG19（上图E列)，两者并没有本质上的区别，只是网络深度不一样。
VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。
两个3x3的卷积层串联相当于1个5x5的卷积层，即一个像素会跟周围5x5的像素产生关联，可以说感受野大小为5x5。而3个3x3的卷积层串联的效果则相当于1个7x7的卷积层;
参数：
https://zhuanlan.zhihu.com/p/41423739
</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——AlexNet模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型">CNN经典算法——AlexNet模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-10T01:27:04.000Z" title="Created 2020-11-10 09:27:04">2020-11-10</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a></span></div><div class="content">2012年，AlexNet横空出世。这个模型的名字来源于论文第一作者的姓名Alex Krizhevsky [1]。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。


第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。

AlexNet第一层中的卷积窗口形状是11×11，strides=4。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。
第二层中的卷积窗口形状减小到5×5；第三、四、五层的卷积窗口大小为3x3.
第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层；而第三、四个卷积层之后没有池化层。

第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。

一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。
另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" title="CNN经典算法——LeNet模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——LeNet模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" title="CNN经典算法——LeNet模型">CNN经典算法——LeNet模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-09T02:59:46.000Z" title="Created 2020-11-09 10:59:46">2020-11-09</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a></span></div><div class="content">LeNet模型介绍

LeNet网络基本架构为：conv1 (6) -&gt; pool1 -&gt; conv2 (16) -&gt; pool2 -&gt; fc3 (120) -&gt; fc4 (84) -&gt; fc5 (10) -&gt; softmax，括号内数字表示channel数。
该网络包含五层，两个卷积（卷积层、池化层)，两个全连接层，一个输出层。
其中卷积层的卷积核大小为5x5，stride=1；池化层为最大池化层，卷积核大小为2x2，strides=2；全连接层的输出个数分别为120， 84， 10.
LeNet模型复现参考：《动手学深度学习》Chapter5
12345import d2lzh as d2limport mxnet as mxfrom mxnet import autograd, gluon, init, ndfrom mxnet.gluon import loss as gloss, nnimport time

基于Sequntial类构造模型经历一次卷积层，其高和宽为(h-k+1)*(w-k+1)；经历一次池化层，其宽和高减半；这个过 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/04/ML-my-hw3-cnn/" title="《机器学习（李宏毅2020spring）》作业3：CNN">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.11416.13666079135464041.262c63a4-3d2e-4fcb-862d-2038cfd9fdf3.50843114-bc48-4a75-9018-4a09fa8ccc4d?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《机器学习（李宏毅2020spring）》作业3：CNN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/04/ML-my-hw3-cnn/" title="《机器学习（李宏毅2020spring）》作业3：CNN">《机器学习（李宏毅2020spring）》作业3：CNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-04T03:09:26.000Z" title="Created 2020-11-04 11:09:26">2020-11-04</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></span></div><div class="content">作业说明：CNN分类问题根据实物照片进行分类，照片的命名规则是“类别_编号.jpg”，类别也是用数字表示，共有11类，Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles/Pasta, Rice, Seafood, Soup, and Vegetable/Fruit；其实具体类别是什么我们可以不用管，只需要训练的时候输入数据，输出类别即可。training 以及 validation 中的照片名名称格式為“类别_编号.jpg”，例如 3_100.jpg 即为类别 3 的照片（编号不重要）testing 中的照片名稱格式為 [编号].jpg数据集需要提前下载下来，解压即可，范例中是从谷歌云下载的，需要翻墙，比较麻烦参考：李宏毅机器学习第三次作业源码
导入需要的包cv2需要额外安装，直接输入命令pip install opencv-python即可完成
12345678910# Import需要的套件import osimport numpy as npimport cv2import torchimport torch ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/31/DL-softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" title="softmax回归模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.53636.14077318991609137.74bb1f9d-01ce-4ec6-aecf-81719875e023.05ba4878-0779-4c67-b36d-5fba9acee597?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="softmax回归模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/31/DL-softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" title="softmax回归模型">softmax回归模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-31T06:38:20.000Z" title="Created 2020-10-31 14:38:20">2020-10-31</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></span></div><div class="content">
线性回归输出结果为连续值，而对于分类问题，需要输出离散值，而softmax可以有效解决这一问题。

softmax回归从零开始实现1234%matplotlib inlineimport d2lzh as d2lfrom mxnet import autograd, nd

读取数据集12batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

初始化参数模型由于像素为28*28，因此输入为784，而输出为10个类别
123456789num_inputs = 784num_outputs = 10W = nd.random.normal(scale=0.01, shape=(num_inputs, num_outputs))b = nd.zeros(num_outputs)#梯度W.attach_grad()b.attach_grad()

softmax运算实现123#看一下三维矩阵的运算X = nd.array([[1, 2, 3], [4, 5, 6]])X.sum(axi ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/30/DL-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" title="Linear Regression线性回归模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.8755.14309757982396439.717bf586-020c-4e5f-9970-26635abeab18.0e591ced-1c02-46b7-a929-0b4f3e984b8a?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linear Regression线性回归模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/30/DL-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" title="Linear Regression线性回归模型">Linear Regression线性回归模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-30T05:39:38.000Z" title="Created 2020-10-30 13:39:38">2020-10-30</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></span></div><div class="content">线性回归的从零开始实现参考：《动手学深度学习》通过利用mxnet框架中的NDArray和autograd来实现一个线性回归的训练过程
导入所需要的包12345%matplotlib inlinefrom IPython import displayfrom matplotlib import pyplot as pltfrom mxnet import autograd, ndimport random

生成数据集我们设定有两个特征值x1， x2，回归模型真实值为y = 2x1 - 3.4x2 + 4.2其中w1 = 2, w2 = -3.4, b = 4.2加入一个随机噪声∈来生成标签label，即y = 2x1 - 3.4x2 + 4.2 + ∈∈符合均值为0，标准差为0.01的正态分布
123456789num_inputs = 2num_examples = 1000true_w = [2, -3.4]true_b = 4.2#随机生成特征值features = nd.random.normal(scale=1, shape=(num_examples, num_inputs ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/29/DL-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="Recurrent Neural Network循环神经网络">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.55268.14092897725620903.14694b0f-5a4e-482f-a8ea-231796e8b5ee.ced4975a-01a5-44c3-8fe9-858a4cb8cb98?w=1083&amp;h=609&amp;q=90&amp;format=jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Recurrent Neural Network循环神经网络"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/29/DL-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="Recurrent Neural Network循环神经网络">Recurrent Neural Network循环神经网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-29T01:43:27.000Z" title="Created 2020-10-29 09:43:27">2020-10-29</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></span></div><div class="content">RNN综述回顾
Why we need  RNN?对于全连接网络，层与层之间是全连接的，但是每层之间的节点是无连接的，因此全连接网络只能够处理单独的输入（即输入之间没有关联），前一个输入和后一个输入时完全没有关系的，无法处理相互之间关联的数据。
例如，我们输入两句话

arrive BeiJing on November 2nd
leave BeiJing on November 2nd

上面这两句话后四个单词都是一样的，但是前两个单词决定了这两句话的含义是完全不同的，即前一个单词对当前单词的含义有很大的影响，而全连接网络无法分辨出这种不同，因此我们需要Neral Network具备记忆功能，即在输入下一个单词之前记住前一个单词。
根据上面我们可以知道RNN用来处理遗传相互依赖的数据流，其用途十分广泛，例如文章中的文字、语音里的音频、股票的价格走势……
The Structural of RNN

包括四个部分：输入层、隐藏层、循环层、输出层；
输入层经过权重求值之后，在隐藏层经过激活函数得到一个值，这个值进行权重求解之后到输出层的同时，也会保存到循环层存储起来，在下一次有输入的时候 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">侯三多</div><div class="author-info__description">追求极致之美</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">16</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HouSanDuo123"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="sticky_layout"><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">Welcome my Blog!</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型"><img src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&amp;q=90&amp;h=1080&amp;w=1920A" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典论文—-NiN模型"/></a><div class="content"><a class="title" href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型">CNN经典论文—-NiN模型</a><time datetime="2020-11-12T08:40:31.000Z" title="Created 2020-11-12 16:40:31">2020-11-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——VGG模型"/></a><div class="content"><a class="title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型">CNN经典算法——VGG模型</a><time datetime="2020-11-10T12:02:31.000Z" title="Created 2020-11-10 20:02:31">2020-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型"><img src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——AlexNet模型"/></a><div class="content"><a class="title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型">CNN经典算法——AlexNet模型</a><time datetime="2020-11-10T01:27:04.000Z" title="Created 2020-11-10 09:27:04">2020-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" title="CNN经典算法——LeNet模型"><img src="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——LeNet模型"/></a><div class="content"><a class="title" href="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" title="CNN经典算法——LeNet模型">CNN经典算法——LeNet模型</a><time datetime="2020-11-09T02:59:46.000Z" title="Created 2020-11-09 10:59:46">2020-11-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/04/ML-my-hw3-cnn/" title="《机器学习（李宏毅2020spring）》作业3：CNN"><img src="https://store-images.s-microsoft.com/image/apps.11416.13666079135464041.262c63a4-3d2e-4fcb-862d-2038cfd9fdf3.50843114-bc48-4a75-9018-4a09fa8ccc4d?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《机器学习（李宏毅2020spring）》作业3：CNN"/></a><div class="content"><a class="title" href="/2020/11/04/ML-my-hw3-cnn/" title="《机器学习（李宏毅2020spring）》作业3：CNN">《机器学习（李宏毅2020spring）》作业3：CNN</a><time datetime="2020-11-04T03:09:26.000Z" title="Created 2020-11-04 11:09:26">2020-11-04</time></div></div></div></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Machine-Learning/" style="font-size: 1.37em; color: rgb(9, 108, 41)">Machine Learning</a><a href="/tags/Hexo/" style="font-size: 1.1em; color: rgb(17, 14, 101)">Hexo</a><a href="/tags/GitHub/" style="font-size: 1.1em; color: rgb(137, 162, 57)">GitHub</a><a href="/tags/Deep-Learning/" style="font-size: 1.5em; color: rgb(148, 126, 138)">Deep Learning</a><a href="/tags/Paper-Recurrence/" style="font-size: 1.23em; color: rgb(118, 160, 41)">Paper Recurrence</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">November 2020</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/10/"><span class="card-archive-list-date">October 2020</span><span class="card-archive-list-count">11</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">16</div></div><div class="webinfo-item"><div class="item-name">Run time :</div><div class="item-count" id="runtimeshow" data-publishDate="2020-10-09T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">15.6k</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2020-11-12T12:16:28.676Z"></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 By 侯三多</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  $.getScript('https://sdk.jinrishici.com/v2/browser/jinrishici.js',function () {
    jinrishici.load(function (result) {
      if (true) {
        var sub = "From Zero to One Hundred".length == 0 ? new Array() : "From Zero to One Hundred".split(',')
        var content = result.data.content
        var both = sub.unshift(content)
        var typed = new Typed('#subtitle', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: true,
          backSpeed: 50,
        })
      } else {
        document.getElementById('subtitle').innerHTML = result.data.content
      }
    })
  })
}

if (true) {
  if (typeof Typed === 'function') subtitleType()
  else $.getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js', subtitleType)
} else {
  subtitleType()
}
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script></div></body></html>